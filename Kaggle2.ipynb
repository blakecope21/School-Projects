{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blakecope21/School-Projects/blob/master/Kaggle2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myokoXrNvSUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, LeakyReLU\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT3-M13MvWRM",
        "colab_type": "code",
        "outputId": "b47975e2-e6e2-477c-d3c5-61859cdcfed7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-937b1990-a4cc-49b1-be20-0fc10fe0fc6e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-937b1990-a4cc-49b1-be20-0fc10fe0fc6e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_X.csv to test_X.csv\n",
            "User uploaded file \"test_X.csv\" with length 61590345 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK8zhz0ww7ur",
        "colab_type": "code",
        "outputId": "cb79771a-18b2-42ba-b1de-422f95ba7326",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03d3e9db-8437-4e24-87d3-1c142c668397\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-03d3e9db-8437-4e24-87d3-1c142c668397\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_X.csv to train_X.csv\n",
            "User uploaded file \"train_X.csv\" with length 184991882 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeGdJWGp0tCR",
        "colab_type": "code",
        "outputId": "bb2b51a1-bbf6-46d4-917e-dd0a5c54df73",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-584a79e1-787e-485c-9778-b416c0081d0c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-584a79e1-787e-485c-9778-b416c0081d0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_Y.csv to train_Y.csv\n",
            "User uploaded file \"train_Y.csv\" with length 2830273 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al4vDBXJ1I0Z",
        "colab_type": "code",
        "outputId": "47a7e67f-1e47-4cb9-978a-27a2c47d9bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        }
      },
      "source": [
        "dfx = pd.read_csv('train_X.csv')\n",
        "dfx.drop('idx', axis=1)\n",
        "dfy = pd.read_csv(\"train_Y.csv\")\n",
        "dfy = dfy.drop('idx', axis=1)\n",
        "dfx_test = pd.read_csv(\"test_X.csv\")\n",
        "dfx_test.drop('idx', axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>...</th>\n",
              "      <th>f45</th>\n",
              "      <th>f46</th>\n",
              "      <th>f47</th>\n",
              "      <th>f48</th>\n",
              "      <th>f49</th>\n",
              "      <th>f50</th>\n",
              "      <th>f51</th>\n",
              "      <th>f52</th>\n",
              "      <th>f53</th>\n",
              "      <th>f54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3259.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>212.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1880.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>2270.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3111.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2814.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>391.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3041.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1655.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2800.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2044.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>1062.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2289.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>418.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>658.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>702.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2863.0</td>\n",
              "      <td>251.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>674.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2957.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1544.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2919.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>408.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>3034.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2285.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>1626.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2983.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>2219.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>1224.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2903.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>1690.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>2664.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2911.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3384.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3967.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3064.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>2594.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>1328.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3239.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>179.0</td>\n",
              "      <td>1771.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2052.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2769.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3872.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>1209.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2414.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>836.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>1392.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2467.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>871.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>1114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3304.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1343.0</td>\n",
              "      <td>209.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>1865.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2973.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1294.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>395.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3293.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1181.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>3371.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2403.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>912.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1298.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3073.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>127.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>4781.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>537.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3237.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1451.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2524.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2794.0</td>\n",
              "      <td>123.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2989.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>371.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>3780.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3156.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>3630.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>722.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3017.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1084.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>3001.0</td>\n",
              "      <td>188.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>198.0</td>\n",
              "      <td>1279.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2718.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1897.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>2706.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3250.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>947.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>3819.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>161.0</td>\n",
              "      <td>2499.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2786.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>390.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>488.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108910</th>\n",
              "      <td>2957.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>859.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2254.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108911</th>\n",
              "      <td>3224.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>726.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>2754.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108912</th>\n",
              "      <td>2873.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3130.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>2594.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108913</th>\n",
              "      <td>3217.0</td>\n",
              "      <td>353.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1460.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>2605.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108914</th>\n",
              "      <td>3044.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>630.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>5934.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>248.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>5287.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108915</th>\n",
              "      <td>3051.0</td>\n",
              "      <td>339.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2507.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>872.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108916</th>\n",
              "      <td>2825.0</td>\n",
              "      <td>338.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>1811.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108917</th>\n",
              "      <td>2756.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>726.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108918</th>\n",
              "      <td>2641.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1012.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>184.0</td>\n",
              "      <td>1892.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108919</th>\n",
              "      <td>1917.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>214.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>698.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108920</th>\n",
              "      <td>2965.0</td>\n",
              "      <td>321.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>5850.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>4811.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108921</th>\n",
              "      <td>2871.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>716.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>793.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>2185.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108922</th>\n",
              "      <td>3384.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2489.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>2493.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108923</th>\n",
              "      <td>2684.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>543.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>812.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108924</th>\n",
              "      <td>2962.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5191.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>1905.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108925</th>\n",
              "      <td>2972.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>4978.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>5267.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108926</th>\n",
              "      <td>2920.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>663.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108927</th>\n",
              "      <td>2612.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2262.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>159.0</td>\n",
              "      <td>1310.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108928</th>\n",
              "      <td>3181.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>1211.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>1984.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108929</th>\n",
              "      <td>3016.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>-37.0</td>\n",
              "      <td>875.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1359.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108930</th>\n",
              "      <td>3132.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>785.0</td>\n",
              "      <td>-12.0</td>\n",
              "      <td>1167.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>1661.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108931</th>\n",
              "      <td>2722.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>1722.0</td>\n",
              "      <td>238.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>1535.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108932</th>\n",
              "      <td>2657.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1866.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>227.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>6860.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108933</th>\n",
              "      <td>2867.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3792.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>232.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>6313.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108934</th>\n",
              "      <td>2701.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1559.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>591.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108935</th>\n",
              "      <td>3037.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>592.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>547.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108936</th>\n",
              "      <td>2926.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>819.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>2138.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108937</th>\n",
              "      <td>2501.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108938</th>\n",
              "      <td>3136.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>789.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>4228.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>223.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>3798.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108939</th>\n",
              "      <td>3039.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>3089.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108940 rows  54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            f1     f2    f3      f4     f5      f6     f7     f8     f9  \\\n",
              "0       3259.0   71.0  15.0   212.0   65.0  1880.0  236.0  210.0  102.0   \n",
              "1       3111.0  235.0  22.0   127.0   25.0  2814.0  176.0  253.0  208.0   \n",
              "2       3041.0  153.0   9.0    85.0   14.0  1655.0  231.0  241.0  141.0   \n",
              "3       2800.0  125.0  18.0   108.0   36.0  2044.0  247.0  224.0   99.0   \n",
              "4       2289.0    9.0  35.0   418.0  132.0   658.0  160.0  149.0  108.0   \n",
              "5       2863.0  251.0  22.0   108.0   42.0   674.0  167.0  249.0  216.0   \n",
              "6       2957.0   45.0  12.0    42.0   -3.0  1544.0  223.0  214.0  123.0   \n",
              "7       2919.0   15.0  20.0   408.0   38.0  1878.0  199.0  195.0  128.0   \n",
              "8       2285.0  327.0  24.0   421.0   78.0   270.0  154.0  205.0  186.0   \n",
              "9       2983.0  203.0  17.0   300.0   90.0  2219.0  209.0  253.0  174.0   \n",
              "10      2903.0   86.0  11.0   319.0   53.0  1690.0  236.0  221.0  115.0   \n",
              "11      2911.0   15.0   5.0   306.0   -1.0  3384.0  215.0  229.0  150.0   \n",
              "12      3064.0  324.0  18.0   162.0  -13.0  2594.0  171.0  217.0  185.0   \n",
              "13      3239.0   44.0  19.0   511.0  179.0  1771.0  221.0  194.0  100.0   \n",
              "14      2769.0   90.0  13.0     0.0    0.0  3872.0  239.0  219.0  109.0   \n",
              "15      2414.0   46.0  17.0    30.0    7.0   836.0  223.0  201.0  107.0   \n",
              "16      2467.0  356.0  25.0   150.0   39.0   871.0  171.0  186.0  146.0   \n",
              "17      3304.0   13.0  11.0   433.0   61.0  1343.0  209.0  217.0  144.0   \n",
              "18      2973.0  190.0  11.0    30.0    8.0  1294.0  220.0  249.0  161.0   \n",
              "19      3293.0   30.0  11.0   120.0   19.0  1181.0  216.0  215.0  133.0   \n",
              "20      2403.0   72.0  18.0   180.0   77.0   912.0  238.0  203.0   90.0   \n",
              "21      3073.0   74.0  13.0   127.0   27.0  4781.0  235.0  215.0  109.0   \n",
              "22      3237.0   81.0  10.0    67.0    7.0  1451.0  234.0  222.0  118.0   \n",
              "23      2794.0  123.0  14.0    90.0    7.0   600.0  243.0  228.0  111.0   \n",
              "24      2989.0   27.0   5.0   371.0   31.0  3780.0  218.0  228.0  147.0   \n",
              "25      3156.0  183.0  23.0   192.0   65.0  3630.0  219.0  248.0  150.0   \n",
              "26      3017.0  229.0  19.0  1084.0  173.0  3001.0  188.0  254.0  198.0   \n",
              "27      2718.0  169.0  14.0     0.0    0.0  1897.0  230.0  245.0  144.0   \n",
              "28      3250.0  348.0  15.0   947.0   59.0  3819.0  190.0  214.0  161.0   \n",
              "29      2786.0  129.0  15.0   360.0  107.0   390.0  244.0  230.0  110.0   \n",
              "...        ...    ...   ...     ...    ...     ...    ...    ...    ...   \n",
              "108910  2957.0   47.0  19.0    67.0    5.0   859.0  223.0  196.0  101.0   \n",
              "108911  3224.0   85.0  11.0   726.0  108.0  1956.0  236.0  221.0  114.0   \n",
              "108912  2873.0   86.0   6.0   270.0   13.0  3130.0  229.0  230.0  134.0   \n",
              "108913  3217.0  353.0  15.0   134.0   44.0  1460.0  194.0  214.0  157.0   \n",
              "108914  3044.0  183.0  13.0   630.0  158.0  5934.0  223.0  248.0  156.0   \n",
              "108915  3051.0  339.0  14.0    30.0   14.0  2507.0  190.0  219.0  168.0   \n",
              "108916  2825.0  338.0   9.0   182.0   32.0  2190.0  201.0  228.0  166.0   \n",
              "108917  2756.0   76.0  16.0   134.0   24.0  2940.0  238.0  208.0   96.0   \n",
              "108918  2641.0  323.0  17.0    67.0   12.0  1012.0  176.0  221.0  184.0   \n",
              "108919  1917.0   43.0  26.0    95.0   50.0   175.0  214.0  172.0   78.0   \n",
              "108920  2965.0  321.0  27.0   335.0  115.0  5850.0  141.0  202.0  196.0   \n",
              "108921  2871.0  302.0  37.0   716.0  496.0   793.0   95.0  196.0  227.0   \n",
              "108922  3384.0   45.0   7.0   192.0    8.0  2489.0  222.0  225.0  138.0   \n",
              "108923  2684.0   61.0   6.0   543.0   17.0   812.0  225.0  228.0  137.0   \n",
              "108924  2962.0  236.0  11.0   301.0   46.0  5191.0  201.0  250.0  185.0   \n",
              "108925  2972.0  331.0   8.0   552.0  145.0  4978.0  201.0  230.0  168.0   \n",
              "108926  2920.0    5.0  19.0   324.0    3.0   663.0  192.0  199.0  140.0   \n",
              "108927  2612.0  350.0  13.0    30.0    7.0  2262.0  197.0  218.0  159.0   \n",
              "108928  3181.0  288.0   7.0   420.0   69.0  1211.0  201.0  240.0  178.0   \n",
              "108929  3016.0  105.0  35.0   190.0  -37.0   875.0  253.0  174.0   17.0   \n",
              "108930  3132.0  344.0  22.0   785.0  -12.0  1167.0  170.0  200.0  165.0   \n",
              "108931  2722.0  135.0  12.0    85.0   -6.0  1722.0  238.0  235.0  125.0   \n",
              "108932  2657.0   74.0   7.0    30.0    0.0  1866.0  229.0  227.0  132.0   \n",
              "108933  2867.0   62.0   4.0   190.0   27.0  3792.0  223.0  232.0  145.0   \n",
              "108934  2701.0   68.0  15.0    30.0   10.0  1559.0  234.0  208.0  101.0   \n",
              "108935  3037.0  164.0   6.0     0.0    0.0   592.0  226.0  242.0  150.0   \n",
              "108936  2926.0  166.0   4.0   162.0   -3.0   819.0  223.0  241.0  153.0   \n",
              "108937  2501.0  107.0  17.0   124.0   29.0   541.0  247.0  218.0   94.0   \n",
              "108938  3136.0  329.0  13.0   789.0  -13.0  4228.0  187.0  223.0  175.0   \n",
              "108939  3039.0  176.0   4.0   150.0   -5.0  3089.0  221.0  241.0  156.0   \n",
              "\n",
              "           f10 ...   f45  f46  f47  f48  f49  f50  f51  f52  f53  f54  \n",
              "0       2270.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
              "1        391.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2        362.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3       1062.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4        702.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "5       1731.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "6       1454.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "7       3034.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "8       1626.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "9       1224.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "10      2664.0 ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "11      3967.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "12      1328.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "13      2052.0 ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "14      1209.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "15      1392.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "16      1114.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "17      1865.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "18       395.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "19      3371.0 ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "20      1298.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "21       537.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "22      2524.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "23       182.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "24      1484.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "25       722.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "26      1279.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "27      2706.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "28      2499.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "29       488.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "...        ... ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
              "108910  2254.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108911  2754.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108912  2594.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108913  2605.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108914  5287.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108915   872.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108916  1811.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108917   726.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108918  1892.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108919   698.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108920  4811.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108921  2185.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108922  2493.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
              "108923  1731.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108924  1905.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108925  5267.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108926   182.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108927  1310.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108928  1984.0 ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108929  1359.0 ...   0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108930  1661.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108931  1535.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108932  6860.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108933  6313.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108934   591.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108935   547.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108936  2138.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108937   313.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108938  3798.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "108939  1265.0 ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[108940 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEP6uz6l1RAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfx = tf.keras.utils.normalize(dfx.values)\n",
        "dfx_test  = tf.keras.utils.normalize(dfx_test.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-CYxi0e1VUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dfx, dfy, test_size=0.25, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVPuOW5r1a3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj_xsZfz1elY",
        "colab_type": "code",
        "outputId": "5e8ec6db-64d4-4a1d-aed0-34acbf3db0ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "net = Sequential()\n",
        "net.add(Dense(units=54, activation=\"relu\"))\n",
        "net.add(Dense(units=216, activation=\"relu\"))\n",
        "net.add(Dense(units=210, activation=\"relu\"))\n",
        "net.add(Dense(units=75, activation=\"relu\"))\n",
        "net.add(Dense(units=69, activation=\"relu\"))\n",
        "net.add(Dense(units=45, activation=\"relu\"))\n",
        "net.add(Dense(units=40, activation=\"relu\"))\n",
        "net.add(Dense(units=8, activation=\"softmax\"))\n",
        "net.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mha05rPj18r1",
        "colab_type": "code",
        "outputId": "e52c3968-5a12-4437-8cc1-8ae1ad74071a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25605
        }
      },
      "source": [
        "model = net.fit(X_train, Y_train, epochs = 750, verbose=1, batch_size=500, validation_data=(X_test, Y_test))\n",
        "prediction = net.predict(dfx_test)\n",
        "prediction2 = np.argmax(prediction, axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 245114 samples, validate on 81705 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/750\n",
            "245114/245114 [==============================] - 8s 32us/sample - loss: 1.2201 - acc: 0.4848 - val_loss: 1.1763 - val_acc: 0.4868\n",
            "Epoch 2/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 1.1228 - acc: 0.4875 - val_loss: 1.0955 - val_acc: 0.4915\n",
            "Epoch 3/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 1.0856 - acc: 0.4963 - val_loss: 1.2438 - val_acc: 0.4439\n",
            "Epoch 4/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 1.0583 - acc: 0.5161 - val_loss: 1.0230 - val_acc: 0.5519\n",
            "Epoch 5/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 1.0077 - acc: 0.5503 - val_loss: 1.0135 - val_acc: 0.5370\n",
            "Epoch 6/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.9594 - acc: 0.5838 - val_loss: 0.8914 - val_acc: 0.6260\n",
            "Epoch 7/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.9518 - acc: 0.5964 - val_loss: 0.9291 - val_acc: 0.6240\n",
            "Epoch 8/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8948 - acc: 0.6168 - val_loss: 0.8436 - val_acc: 0.6397\n",
            "Epoch 9/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8663 - acc: 0.6320 - val_loss: 0.8223 - val_acc: 0.6428\n",
            "Epoch 10/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8495 - acc: 0.6373 - val_loss: 0.8253 - val_acc: 0.6437\n",
            "Epoch 11/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8349 - acc: 0.6441 - val_loss: 0.7945 - val_acc: 0.6731\n",
            "Epoch 12/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8220 - acc: 0.6496 - val_loss: 0.8032 - val_acc: 0.6570\n",
            "Epoch 13/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.8095 - acc: 0.6547 - val_loss: 0.7941 - val_acc: 0.6648\n",
            "Epoch 14/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8046 - acc: 0.6566 - val_loss: 0.7714 - val_acc: 0.6732\n",
            "Epoch 15/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.8002 - acc: 0.6598 - val_loss: 0.9637 - val_acc: 0.5748\n",
            "Epoch 16/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7987 - acc: 0.6584 - val_loss: 0.7717 - val_acc: 0.6764\n",
            "Epoch 17/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.8000 - acc: 0.6578 - val_loss: 0.7662 - val_acc: 0.6866\n",
            "Epoch 18/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7927 - acc: 0.6622 - val_loss: 0.9535 - val_acc: 0.5676\n",
            "Epoch 19/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7825 - acc: 0.6664 - val_loss: 0.7885 - val_acc: 0.6620\n",
            "Epoch 20/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7803 - acc: 0.6668 - val_loss: 0.7517 - val_acc: 0.6816\n",
            "Epoch 21/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7770 - acc: 0.6675 - val_loss: 0.8253 - val_acc: 0.6372\n",
            "Epoch 22/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7761 - acc: 0.6699 - val_loss: 0.7948 - val_acc: 0.6550\n",
            "Epoch 23/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7726 - acc: 0.6700 - val_loss: 0.7326 - val_acc: 0.6925\n",
            "Epoch 24/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7676 - acc: 0.6723 - val_loss: 0.7460 - val_acc: 0.6821\n",
            "Epoch 25/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7640 - acc: 0.6737 - val_loss: 0.7261 - val_acc: 0.6948\n",
            "Epoch 26/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.7630 - acc: 0.6735 - val_loss: 0.7421 - val_acc: 0.6890\n",
            "Epoch 27/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7519 - acc: 0.6784 - val_loss: 0.7874 - val_acc: 0.6555\n",
            "Epoch 28/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7550 - acc: 0.6761 - val_loss: 0.7685 - val_acc: 0.6594\n",
            "Epoch 29/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.7476 - acc: 0.6796 - val_loss: 0.7176 - val_acc: 0.7015\n",
            "Epoch 30/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.7511 - acc: 0.6786 - val_loss: 0.7155 - val_acc: 0.6933\n",
            "Epoch 31/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7439 - acc: 0.6806 - val_loss: 0.9320 - val_acc: 0.6001\n",
            "Epoch 32/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7392 - acc: 0.6829 - val_loss: 0.7276 - val_acc: 0.6902\n",
            "Epoch 33/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.7329 - acc: 0.6860 - val_loss: 0.7350 - val_acc: 0.6838\n",
            "Epoch 34/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.7350 - acc: 0.6846 - val_loss: 0.7005 - val_acc: 0.7041\n",
            "Epoch 35/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7316 - acc: 0.6845 - val_loss: 0.7041 - val_acc: 0.6973\n",
            "Epoch 36/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7295 - acc: 0.6862 - val_loss: 0.7269 - val_acc: 0.6835\n",
            "Epoch 37/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.7150 - acc: 0.6924 - val_loss: 0.7225 - val_acc: 0.6888\n",
            "Epoch 38/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7183 - acc: 0.6912 - val_loss: 0.8163 - val_acc: 0.6416\n",
            "Epoch 39/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.7273 - acc: 0.6871 - val_loss: 0.7121 - val_acc: 0.6959\n",
            "Epoch 40/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7191 - acc: 0.6893 - val_loss: 0.7073 - val_acc: 0.7007\n",
            "Epoch 41/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7124 - acc: 0.6921 - val_loss: 0.7794 - val_acc: 0.6506\n",
            "Epoch 42/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7098 - acc: 0.6941 - val_loss: 0.7305 - val_acc: 0.6801\n",
            "Epoch 43/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.7136 - acc: 0.6908 - val_loss: 0.6919 - val_acc: 0.7064\n",
            "Epoch 44/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.7050 - acc: 0.6954 - val_loss: 0.8440 - val_acc: 0.6175\n",
            "Epoch 45/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6975 - acc: 0.6993 - val_loss: 0.7050 - val_acc: 0.6926\n",
            "Epoch 46/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6974 - acc: 0.6977 - val_loss: 0.6762 - val_acc: 0.7110\n",
            "Epoch 47/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6971 - acc: 0.6992 - val_loss: 0.7861 - val_acc: 0.6504\n",
            "Epoch 48/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6990 - acc: 0.6967 - val_loss: 0.6614 - val_acc: 0.7201\n",
            "Epoch 49/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6920 - acc: 0.6997 - val_loss: 1.1720 - val_acc: 0.5313\n",
            "Epoch 50/750\n",
            "245114/245114 [==============================] - 7s 27us/sample - loss: 0.6940 - acc: 0.6988 - val_loss: 0.6916 - val_acc: 0.7012\n",
            "Epoch 51/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6839 - acc: 0.7037 - val_loss: 0.7136 - val_acc: 0.6817\n",
            "Epoch 52/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6830 - acc: 0.7028 - val_loss: 0.6806 - val_acc: 0.7120\n",
            "Epoch 53/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6876 - acc: 0.7002 - val_loss: 0.6547 - val_acc: 0.7189\n",
            "Epoch 54/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6781 - acc: 0.7046 - val_loss: 0.6763 - val_acc: 0.7056\n",
            "Epoch 55/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6721 - acc: 0.7079 - val_loss: 0.6440 - val_acc: 0.7235\n",
            "Epoch 56/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6784 - acc: 0.7042 - val_loss: 0.6383 - val_acc: 0.7259\n",
            "Epoch 57/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6667 - acc: 0.7091 - val_loss: 0.6515 - val_acc: 0.7181\n",
            "Epoch 58/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6625 - acc: 0.7111 - val_loss: 0.7105 - val_acc: 0.6935\n",
            "Epoch 59/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6680 - acc: 0.7086 - val_loss: 0.6349 - val_acc: 0.7265\n",
            "Epoch 60/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6623 - acc: 0.7116 - val_loss: 0.6259 - val_acc: 0.7278\n",
            "Epoch 61/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6630 - acc: 0.7105 - val_loss: 0.6364 - val_acc: 0.7260\n",
            "Epoch 62/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6512 - acc: 0.7159 - val_loss: 0.7376 - val_acc: 0.6665\n",
            "Epoch 63/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6495 - acc: 0.7170 - val_loss: 0.6171 - val_acc: 0.7348\n",
            "Epoch 64/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6462 - acc: 0.7185 - val_loss: 0.6672 - val_acc: 0.6996\n",
            "Epoch 65/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6493 - acc: 0.7172 - val_loss: 0.6162 - val_acc: 0.7354\n",
            "Epoch 66/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6351 - acc: 0.7232 - val_loss: 0.6192 - val_acc: 0.7321\n",
            "Epoch 67/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6439 - acc: 0.7188 - val_loss: 0.7071 - val_acc: 0.6864\n",
            "Epoch 68/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6423 - acc: 0.7197 - val_loss: 0.6119 - val_acc: 0.7340\n",
            "Epoch 69/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6348 - acc: 0.7234 - val_loss: 0.6135 - val_acc: 0.7341\n",
            "Epoch 70/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6345 - acc: 0.7230 - val_loss: 0.7013 - val_acc: 0.6805\n",
            "Epoch 71/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6305 - acc: 0.7248 - val_loss: 0.6179 - val_acc: 0.7301\n",
            "Epoch 72/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6245 - acc: 0.7274 - val_loss: 0.9245 - val_acc: 0.6057\n",
            "Epoch 73/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.6253 - acc: 0.7263 - val_loss: 0.5907 - val_acc: 0.7472\n",
            "Epoch 74/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6158 - acc: 0.7322 - val_loss: 0.6314 - val_acc: 0.7166\n",
            "Epoch 75/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6145 - acc: 0.7321 - val_loss: 0.6106 - val_acc: 0.7389\n",
            "Epoch 76/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6154 - acc: 0.7306 - val_loss: 0.6367 - val_acc: 0.7220\n",
            "Epoch 77/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.6103 - acc: 0.7325 - val_loss: 0.6550 - val_acc: 0.7073\n",
            "Epoch 78/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.6170 - acc: 0.7294 - val_loss: 0.5921 - val_acc: 0.7439\n",
            "Epoch 79/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.6050 - acc: 0.7358 - val_loss: 0.6146 - val_acc: 0.7261\n",
            "Epoch 80/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6028 - acc: 0.7365 - val_loss: 0.6030 - val_acc: 0.7356\n",
            "Epoch 81/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.6030 - acc: 0.7363 - val_loss: 0.6943 - val_acc: 0.6891\n",
            "Epoch 82/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5943 - acc: 0.7392 - val_loss: 0.6225 - val_acc: 0.7252\n",
            "Epoch 83/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5946 - acc: 0.7390 - val_loss: 0.5846 - val_acc: 0.7480\n",
            "Epoch 84/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5859 - acc: 0.7436 - val_loss: 0.5840 - val_acc: 0.7442\n",
            "Epoch 85/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.5814 - acc: 0.7453 - val_loss: 0.6657 - val_acc: 0.7097\n",
            "Epoch 86/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5846 - acc: 0.7437 - val_loss: 0.6300 - val_acc: 0.7197\n",
            "Epoch 87/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5779 - acc: 0.7461 - val_loss: 0.6324 - val_acc: 0.7189\n",
            "Epoch 88/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5730 - acc: 0.7478 - val_loss: 0.6734 - val_acc: 0.7056\n",
            "Epoch 89/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5660 - acc: 0.7521 - val_loss: 0.5399 - val_acc: 0.7687\n",
            "Epoch 90/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5823 - acc: 0.7437 - val_loss: 0.5713 - val_acc: 0.7501\n",
            "Epoch 91/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5576 - acc: 0.7557 - val_loss: 0.5402 - val_acc: 0.7671\n",
            "Epoch 92/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5647 - acc: 0.7516 - val_loss: 0.5681 - val_acc: 0.7478\n",
            "Epoch 93/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5667 - acc: 0.7512 - val_loss: 0.5493 - val_acc: 0.7676\n",
            "Epoch 94/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5633 - acc: 0.7524 - val_loss: 0.5230 - val_acc: 0.7742\n",
            "Epoch 95/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5607 - acc: 0.7534 - val_loss: 0.5634 - val_acc: 0.7531\n",
            "Epoch 96/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5499 - acc: 0.7578 - val_loss: 0.5222 - val_acc: 0.7772\n",
            "Epoch 97/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5407 - acc: 0.7624 - val_loss: 0.5292 - val_acc: 0.7707\n",
            "Epoch 98/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5551 - acc: 0.7564 - val_loss: 0.5651 - val_acc: 0.7529\n",
            "Epoch 99/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5358 - acc: 0.7638 - val_loss: 0.5118 - val_acc: 0.7829\n",
            "Epoch 100/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5420 - acc: 0.7621 - val_loss: 0.5463 - val_acc: 0.7594\n",
            "Epoch 101/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5408 - acc: 0.7616 - val_loss: 0.5525 - val_acc: 0.7571\n",
            "Epoch 102/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5334 - acc: 0.7658 - val_loss: 0.5482 - val_acc: 0.7601\n",
            "Epoch 103/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5467 - acc: 0.7588 - val_loss: 0.5233 - val_acc: 0.7739\n",
            "Epoch 104/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5259 - acc: 0.7690 - val_loss: 0.5218 - val_acc: 0.7744\n",
            "Epoch 105/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5351 - acc: 0.7645 - val_loss: 0.5261 - val_acc: 0.7771\n",
            "Epoch 106/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5280 - acc: 0.7680 - val_loss: 0.7766 - val_acc: 0.6702\n",
            "Epoch 107/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5329 - acc: 0.7653 - val_loss: 0.5006 - val_acc: 0.7844\n",
            "Epoch 108/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5323 - acc: 0.7668 - val_loss: 0.5080 - val_acc: 0.7803\n",
            "Epoch 109/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5236 - acc: 0.7707 - val_loss: 0.5327 - val_acc: 0.7688\n",
            "Epoch 110/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5221 - acc: 0.7710 - val_loss: 0.4915 - val_acc: 0.7885\n",
            "Epoch 111/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5159 - acc: 0.7738 - val_loss: 0.4963 - val_acc: 0.7894\n",
            "Epoch 112/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5177 - acc: 0.7729 - val_loss: 0.5587 - val_acc: 0.7571\n",
            "Epoch 113/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5132 - acc: 0.7744 - val_loss: 0.5086 - val_acc: 0.7819\n",
            "Epoch 114/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5183 - acc: 0.7733 - val_loss: 0.6986 - val_acc: 0.6976\n",
            "Epoch 115/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5136 - acc: 0.7747 - val_loss: 0.5735 - val_acc: 0.7499\n",
            "Epoch 116/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5232 - acc: 0.7705 - val_loss: 0.7269 - val_acc: 0.6898\n",
            "Epoch 117/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5121 - acc: 0.7755 - val_loss: 0.5943 - val_acc: 0.7429\n",
            "Epoch 118/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.5093 - acc: 0.7775 - val_loss: 0.7212 - val_acc: 0.6951\n",
            "Epoch 119/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5050 - acc: 0.7784 - val_loss: 0.5119 - val_acc: 0.7843\n",
            "Epoch 120/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4985 - acc: 0.7822 - val_loss: 0.5354 - val_acc: 0.7649\n",
            "Epoch 121/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.5037 - acc: 0.7796 - val_loss: 0.4920 - val_acc: 0.7882\n",
            "Epoch 122/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.4998 - acc: 0.7802 - val_loss: 0.5041 - val_acc: 0.7810\n",
            "Epoch 123/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4934 - acc: 0.7844 - val_loss: 0.6047 - val_acc: 0.7375\n",
            "Epoch 124/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4984 - acc: 0.7821 - val_loss: 0.4942 - val_acc: 0.7838\n",
            "Epoch 125/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4926 - acc: 0.7842 - val_loss: 0.4758 - val_acc: 0.7959\n",
            "Epoch 126/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4923 - acc: 0.7850 - val_loss: 0.4983 - val_acc: 0.7878\n",
            "Epoch 127/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4834 - acc: 0.7886 - val_loss: 0.4816 - val_acc: 0.7908\n",
            "Epoch 128/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4931 - acc: 0.7849 - val_loss: 0.5621 - val_acc: 0.7568\n",
            "Epoch 129/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.4846 - acc: 0.7885 - val_loss: 0.4676 - val_acc: 0.8001\n",
            "Epoch 130/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.4928 - acc: 0.7841 - val_loss: 0.4697 - val_acc: 0.7997\n",
            "Epoch 131/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4731 - acc: 0.7936 - val_loss: 0.4870 - val_acc: 0.7937\n",
            "Epoch 132/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4819 - acc: 0.7890 - val_loss: 0.8040 - val_acc: 0.6737\n",
            "Epoch 133/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4876 - acc: 0.7873 - val_loss: 0.4834 - val_acc: 0.7936\n",
            "Epoch 134/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4767 - acc: 0.7916 - val_loss: 0.4760 - val_acc: 0.7958\n",
            "Epoch 135/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4794 - acc: 0.7915 - val_loss: 0.4871 - val_acc: 0.7916\n",
            "Epoch 136/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4765 - acc: 0.7919 - val_loss: 0.5210 - val_acc: 0.7773\n",
            "Epoch 137/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4740 - acc: 0.7932 - val_loss: 0.4910 - val_acc: 0.7887\n",
            "Epoch 138/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4658 - acc: 0.7970 - val_loss: 0.4752 - val_acc: 0.7971\n",
            "Epoch 139/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4745 - acc: 0.7936 - val_loss: 0.4784 - val_acc: 0.7941\n",
            "Epoch 140/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4717 - acc: 0.7945 - val_loss: 0.4678 - val_acc: 0.7992\n",
            "Epoch 141/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4688 - acc: 0.7957 - val_loss: 0.4980 - val_acc: 0.7863\n",
            "Epoch 142/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4772 - acc: 0.7924 - val_loss: 0.4813 - val_acc: 0.7937\n",
            "Epoch 143/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4640 - acc: 0.7984 - val_loss: 0.4623 - val_acc: 0.8066\n",
            "Epoch 144/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4619 - acc: 0.7983 - val_loss: 0.5022 - val_acc: 0.7821\n",
            "Epoch 145/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4709 - acc: 0.7948 - val_loss: 0.4810 - val_acc: 0.7966\n",
            "Epoch 146/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4612 - acc: 0.7998 - val_loss: 0.5086 - val_acc: 0.7798\n",
            "Epoch 147/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4630 - acc: 0.7981 - val_loss: 0.5485 - val_acc: 0.7641\n",
            "Epoch 148/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4549 - acc: 0.8018 - val_loss: 0.4581 - val_acc: 0.8074\n",
            "Epoch 149/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4629 - acc: 0.7980 - val_loss: 0.5808 - val_acc: 0.7469\n",
            "Epoch 150/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4517 - acc: 0.8032 - val_loss: 0.4533 - val_acc: 0.8088\n",
            "Epoch 151/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4678 - acc: 0.7963 - val_loss: 0.4945 - val_acc: 0.7909\n",
            "Epoch 152/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4628 - acc: 0.7983 - val_loss: 0.4516 - val_acc: 0.8093\n",
            "Epoch 153/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4542 - acc: 0.8022 - val_loss: 0.4619 - val_acc: 0.8049\n",
            "Epoch 154/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4548 - acc: 0.8014 - val_loss: 0.4541 - val_acc: 0.8084\n",
            "Epoch 155/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4483 - acc: 0.8060 - val_loss: 0.4897 - val_acc: 0.7899\n",
            "Epoch 156/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4514 - acc: 0.8037 - val_loss: 0.6095 - val_acc: 0.7338\n",
            "Epoch 157/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4540 - acc: 0.8025 - val_loss: 0.5287 - val_acc: 0.7732\n",
            "Epoch 158/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4533 - acc: 0.8023 - val_loss: 0.4835 - val_acc: 0.7942\n",
            "Epoch 159/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4404 - acc: 0.8086 - val_loss: 0.4591 - val_acc: 0.8059\n",
            "Epoch 160/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4431 - acc: 0.8081 - val_loss: 0.5973 - val_acc: 0.7447\n",
            "Epoch 161/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4460 - acc: 0.8071 - val_loss: 0.5570 - val_acc: 0.7577\n",
            "Epoch 162/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4541 - acc: 0.8031 - val_loss: 0.4896 - val_acc: 0.7914\n",
            "Epoch 163/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4430 - acc: 0.8068 - val_loss: 0.4382 - val_acc: 0.8175\n",
            "Epoch 164/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4408 - acc: 0.8079 - val_loss: 0.5690 - val_acc: 0.7569\n",
            "Epoch 165/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.4413 - acc: 0.8080 - val_loss: 0.4990 - val_acc: 0.7832\n",
            "Epoch 166/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4412 - acc: 0.8079 - val_loss: 0.4530 - val_acc: 0.8103\n",
            "Epoch 167/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4439 - acc: 0.8067 - val_loss: 0.5829 - val_acc: 0.7525\n",
            "Epoch 168/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.4524 - acc: 0.8026 - val_loss: 0.4654 - val_acc: 0.8051\n",
            "Epoch 169/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.4326 - acc: 0.8118 - val_loss: 0.5600 - val_acc: 0.7569\n",
            "Epoch 170/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4291 - acc: 0.8138 - val_loss: 0.6819 - val_acc: 0.7107\n",
            "Epoch 171/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4380 - acc: 0.8095 - val_loss: 0.4671 - val_acc: 0.8047\n",
            "Epoch 172/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4389 - acc: 0.8096 - val_loss: 0.4702 - val_acc: 0.8028\n",
            "Epoch 173/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4336 - acc: 0.8117 - val_loss: 0.4415 - val_acc: 0.8159\n",
            "Epoch 174/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4254 - acc: 0.8154 - val_loss: 0.6178 - val_acc: 0.7399\n",
            "Epoch 175/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4315 - acc: 0.8128 - val_loss: 0.5537 - val_acc: 0.7648\n",
            "Epoch 176/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4373 - acc: 0.8100 - val_loss: 0.7693 - val_acc: 0.6943\n",
            "Epoch 177/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4353 - acc: 0.8119 - val_loss: 0.4817 - val_acc: 0.7966\n",
            "Epoch 178/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4401 - acc: 0.8086 - val_loss: 0.4761 - val_acc: 0.7993\n",
            "Epoch 179/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4200 - acc: 0.8187 - val_loss: 0.5841 - val_acc: 0.7529\n",
            "Epoch 180/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4381 - acc: 0.8103 - val_loss: 0.5916 - val_acc: 0.7552\n",
            "Epoch 181/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4155 - acc: 0.8200 - val_loss: 0.4339 - val_acc: 0.8204\n",
            "Epoch 182/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4294 - acc: 0.8136 - val_loss: 0.4665 - val_acc: 0.8051\n",
            "Epoch 183/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4301 - acc: 0.8135 - val_loss: 0.4344 - val_acc: 0.8177\n",
            "Epoch 184/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4267 - acc: 0.8148 - val_loss: 0.4430 - val_acc: 0.8160\n",
            "Epoch 185/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4152 - acc: 0.8197 - val_loss: 0.4752 - val_acc: 0.8024\n",
            "Epoch 186/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4238 - acc: 0.8160 - val_loss: 0.4447 - val_acc: 0.8169\n",
            "Epoch 187/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4208 - acc: 0.8179 - val_loss: 0.6355 - val_acc: 0.7356\n",
            "Epoch 188/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4104 - acc: 0.8226 - val_loss: 0.5039 - val_acc: 0.7887\n",
            "Epoch 189/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4110 - acc: 0.8227 - val_loss: 0.9800 - val_acc: 0.6535\n",
            "Epoch 190/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4239 - acc: 0.8170 - val_loss: 0.5002 - val_acc: 0.7868\n",
            "Epoch 191/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4310 - acc: 0.8124 - val_loss: 0.5705 - val_acc: 0.7570\n",
            "Epoch 192/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4132 - acc: 0.8213 - val_loss: 0.6789 - val_acc: 0.7250\n",
            "Epoch 193/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4116 - acc: 0.8222 - val_loss: 0.4276 - val_acc: 0.8221\n",
            "Epoch 194/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4125 - acc: 0.8220 - val_loss: 0.8097 - val_acc: 0.6884\n",
            "Epoch 195/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4193 - acc: 0.8176 - val_loss: 0.4233 - val_acc: 0.8245\n",
            "Epoch 196/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4141 - acc: 0.8216 - val_loss: 0.4433 - val_acc: 0.8126\n",
            "Epoch 197/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4091 - acc: 0.8227 - val_loss: 0.4392 - val_acc: 0.8177\n",
            "Epoch 198/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4092 - acc: 0.8233 - val_loss: 0.4408 - val_acc: 0.8161\n",
            "Epoch 199/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4138 - acc: 0.8207 - val_loss: 0.4640 - val_acc: 0.8027\n",
            "Epoch 200/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4140 - acc: 0.8198 - val_loss: 0.5800 - val_acc: 0.7558\n",
            "Epoch 201/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4101 - acc: 0.8221 - val_loss: 0.4921 - val_acc: 0.7926\n",
            "Epoch 202/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4163 - acc: 0.8192 - val_loss: 0.4395 - val_acc: 0.8177\n",
            "Epoch 203/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3948 - acc: 0.8300 - val_loss: 0.4241 - val_acc: 0.8254\n",
            "Epoch 204/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4021 - acc: 0.8269 - val_loss: 0.4814 - val_acc: 0.7966\n",
            "Epoch 205/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.4110 - acc: 0.8219 - val_loss: 0.4573 - val_acc: 0.8070\n",
            "Epoch 206/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4165 - acc: 0.8195 - val_loss: 0.4950 - val_acc: 0.7911\n",
            "Epoch 207/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4041 - acc: 0.8249 - val_loss: 0.4463 - val_acc: 0.8133\n",
            "Epoch 208/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4156 - acc: 0.8201 - val_loss: 0.5662 - val_acc: 0.7589\n",
            "Epoch 209/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.4056 - acc: 0.8244 - val_loss: 0.4171 - val_acc: 0.8307\n",
            "Epoch 210/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4014 - acc: 0.8267 - val_loss: 0.4837 - val_acc: 0.7957\n",
            "Epoch 211/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4024 - acc: 0.8259 - val_loss: 0.4850 - val_acc: 0.7956\n",
            "Epoch 212/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4021 - acc: 0.8256 - val_loss: 0.4238 - val_acc: 0.8254\n",
            "Epoch 213/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4125 - acc: 0.8218 - val_loss: 0.6276 - val_acc: 0.7391\n",
            "Epoch 214/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3861 - acc: 0.8334 - val_loss: 0.4302 - val_acc: 0.8204\n",
            "Epoch 215/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.4126 - acc: 0.8219 - val_loss: 0.4258 - val_acc: 0.8262\n",
            "Epoch 216/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3980 - acc: 0.8281 - val_loss: 0.4529 - val_acc: 0.8120\n",
            "Epoch 217/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3951 - acc: 0.8295 - val_loss: 0.6936 - val_acc: 0.7121\n",
            "Epoch 218/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4018 - acc: 0.8266 - val_loss: 0.4251 - val_acc: 0.8258\n",
            "Epoch 219/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3988 - acc: 0.8281 - val_loss: 0.4470 - val_acc: 0.8143\n",
            "Epoch 220/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3966 - acc: 0.8289 - val_loss: 0.4330 - val_acc: 0.8220\n",
            "Epoch 221/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4015 - acc: 0.8267 - val_loss: 0.4127 - val_acc: 0.8325\n",
            "Epoch 222/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3936 - acc: 0.8304 - val_loss: 0.5107 - val_acc: 0.7862\n",
            "Epoch 223/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3954 - acc: 0.8294 - val_loss: 0.4032 - val_acc: 0.8347\n",
            "Epoch 224/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3891 - acc: 0.8317 - val_loss: 0.4675 - val_acc: 0.8045\n",
            "Epoch 225/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3938 - acc: 0.8300 - val_loss: 0.4279 - val_acc: 0.8243\n",
            "Epoch 226/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3977 - acc: 0.8283 - val_loss: 0.4109 - val_acc: 0.8309\n",
            "Epoch 227/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3959 - acc: 0.8292 - val_loss: 0.4595 - val_acc: 0.8048\n",
            "Epoch 228/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3818 - acc: 0.8354 - val_loss: 0.4972 - val_acc: 0.7933\n",
            "Epoch 229/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3911 - acc: 0.8314 - val_loss: 0.4074 - val_acc: 0.8333\n",
            "Epoch 230/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3888 - acc: 0.8319 - val_loss: 0.4412 - val_acc: 0.8164\n",
            "Epoch 231/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.4048 - acc: 0.8256 - val_loss: 0.4346 - val_acc: 0.8199\n",
            "Epoch 232/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3825 - acc: 0.8354 - val_loss: 0.4302 - val_acc: 0.8249\n",
            "Epoch 233/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3927 - acc: 0.8307 - val_loss: 0.4273 - val_acc: 0.8247\n",
            "Epoch 234/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3810 - acc: 0.8362 - val_loss: 0.4146 - val_acc: 0.8308\n",
            "Epoch 235/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3973 - acc: 0.8289 - val_loss: 0.6096 - val_acc: 0.7485\n",
            "Epoch 236/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3839 - acc: 0.8354 - val_loss: 0.4233 - val_acc: 0.8259\n",
            "Epoch 237/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3806 - acc: 0.8360 - val_loss: 0.4181 - val_acc: 0.8290\n",
            "Epoch 238/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3824 - acc: 0.8345 - val_loss: 0.4908 - val_acc: 0.7988\n",
            "Epoch 239/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3884 - acc: 0.8325 - val_loss: 0.4918 - val_acc: 0.7919\n",
            "Epoch 240/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3830 - acc: 0.8347 - val_loss: 0.4207 - val_acc: 0.8270\n",
            "Epoch 241/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3756 - acc: 0.8385 - val_loss: 0.4265 - val_acc: 0.8262\n",
            "Epoch 242/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3870 - acc: 0.8329 - val_loss: 0.5230 - val_acc: 0.7831\n",
            "Epoch 243/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3799 - acc: 0.8361 - val_loss: 0.5426 - val_acc: 0.7728\n",
            "Epoch 244/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3785 - acc: 0.8376 - val_loss: 0.3995 - val_acc: 0.8384\n",
            "Epoch 245/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3847 - acc: 0.8349 - val_loss: 0.4577 - val_acc: 0.8097\n",
            "Epoch 246/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3905 - acc: 0.8309 - val_loss: 0.4500 - val_acc: 0.8148\n",
            "Epoch 247/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3680 - acc: 0.8419 - val_loss: 0.4007 - val_acc: 0.8369\n",
            "Epoch 248/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3888 - acc: 0.8327 - val_loss: 0.4268 - val_acc: 0.8262\n",
            "Epoch 249/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3691 - acc: 0.8417 - val_loss: 0.4339 - val_acc: 0.8234\n",
            "Epoch 250/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3790 - acc: 0.8363 - val_loss: 0.6308 - val_acc: 0.7487\n",
            "Epoch 251/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3768 - acc: 0.8387 - val_loss: 0.4551 - val_acc: 0.8098\n",
            "Epoch 252/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.3759 - acc: 0.8386 - val_loss: 0.4542 - val_acc: 0.8131\n",
            "Epoch 253/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3773 - acc: 0.8370 - val_loss: 0.4492 - val_acc: 0.8153\n",
            "Epoch 254/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3734 - acc: 0.8393 - val_loss: 0.4360 - val_acc: 0.8201\n",
            "Epoch 255/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3765 - acc: 0.8368 - val_loss: 0.4879 - val_acc: 0.7985\n",
            "Epoch 256/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3763 - acc: 0.8376 - val_loss: 0.4553 - val_acc: 0.8124\n",
            "Epoch 257/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3715 - acc: 0.8402 - val_loss: 0.4959 - val_acc: 0.7976\n",
            "Epoch 258/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3714 - acc: 0.8405 - val_loss: 0.5773 - val_acc: 0.7658\n",
            "Epoch 259/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3730 - acc: 0.8394 - val_loss: 0.4260 - val_acc: 0.8248\n",
            "Epoch 260/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3747 - acc: 0.8395 - val_loss: 0.4151 - val_acc: 0.8323\n",
            "Epoch 261/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3758 - acc: 0.8387 - val_loss: 0.4310 - val_acc: 0.8248\n",
            "Epoch 262/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3696 - acc: 0.8409 - val_loss: 0.4298 - val_acc: 0.8216\n",
            "Epoch 263/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3641 - acc: 0.8440 - val_loss: 0.4155 - val_acc: 0.8299\n",
            "Epoch 264/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3650 - acc: 0.8428 - val_loss: 0.4622 - val_acc: 0.8074\n",
            "Epoch 265/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3767 - acc: 0.8383 - val_loss: 0.4343 - val_acc: 0.8208\n",
            "Epoch 266/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3639 - acc: 0.8441 - val_loss: 0.4500 - val_acc: 0.8168\n",
            "Epoch 267/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3743 - acc: 0.8386 - val_loss: 0.5192 - val_acc: 0.7815\n",
            "Epoch 268/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3712 - acc: 0.8409 - val_loss: 0.4234 - val_acc: 0.8275\n",
            "Epoch 269/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3583 - acc: 0.8453 - val_loss: 0.4934 - val_acc: 0.8042\n",
            "Epoch 270/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3618 - acc: 0.8455 - val_loss: 0.4410 - val_acc: 0.8191\n",
            "Epoch 271/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3577 - acc: 0.8467 - val_loss: 0.4115 - val_acc: 0.8330\n",
            "Epoch 272/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3721 - acc: 0.8407 - val_loss: 0.4021 - val_acc: 0.8385\n",
            "Epoch 273/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3639 - acc: 0.8440 - val_loss: 0.4151 - val_acc: 0.8315\n",
            "Epoch 274/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3635 - acc: 0.8435 - val_loss: 0.4238 - val_acc: 0.8280\n",
            "Epoch 275/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3580 - acc: 0.8470 - val_loss: 0.3999 - val_acc: 0.8406\n",
            "Epoch 276/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3667 - acc: 0.8426 - val_loss: 0.4115 - val_acc: 0.8348\n",
            "Epoch 277/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3613 - acc: 0.8454 - val_loss: 0.4555 - val_acc: 0.8124\n",
            "Epoch 278/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3537 - acc: 0.8477 - val_loss: 0.4664 - val_acc: 0.8097\n",
            "Epoch 279/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3583 - acc: 0.8468 - val_loss: 0.4666 - val_acc: 0.8102\n",
            "Epoch 280/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3577 - acc: 0.8472 - val_loss: 0.6494 - val_acc: 0.7451\n",
            "Epoch 281/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3627 - acc: 0.8443 - val_loss: 0.4944 - val_acc: 0.7967\n",
            "Epoch 282/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3592 - acc: 0.8467 - val_loss: 0.5195 - val_acc: 0.7861\n",
            "Epoch 283/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3748 - acc: 0.8395 - val_loss: 0.4055 - val_acc: 0.8379\n",
            "Epoch 284/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3579 - acc: 0.8473 - val_loss: 0.4728 - val_acc: 0.8046\n",
            "Epoch 285/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3632 - acc: 0.8442 - val_loss: 0.4220 - val_acc: 0.8289\n",
            "Epoch 286/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3546 - acc: 0.8476 - val_loss: 0.4481 - val_acc: 0.8182\n",
            "Epoch 287/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3654 - acc: 0.8429 - val_loss: 0.4303 - val_acc: 0.8229\n",
            "Epoch 288/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3504 - acc: 0.8497 - val_loss: 0.6203 - val_acc: 0.7508\n",
            "Epoch 289/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3680 - acc: 0.8424 - val_loss: 0.5039 - val_acc: 0.7929\n",
            "Epoch 290/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3539 - acc: 0.8484 - val_loss: 0.3947 - val_acc: 0.8443\n",
            "Epoch 291/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3664 - acc: 0.8438 - val_loss: 0.6225 - val_acc: 0.7533\n",
            "Epoch 292/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3635 - acc: 0.8437 - val_loss: 0.4176 - val_acc: 0.8294\n",
            "Epoch 293/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3549 - acc: 0.8483 - val_loss: 0.4097 - val_acc: 0.8357\n",
            "Epoch 294/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3609 - acc: 0.8450 - val_loss: 0.4357 - val_acc: 0.8257\n",
            "Epoch 295/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.3578 - acc: 0.8463 - val_loss: 0.4127 - val_acc: 0.8338\n",
            "Epoch 296/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3507 - acc: 0.8493 - val_loss: 0.4444 - val_acc: 0.8207\n",
            "Epoch 297/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3554 - acc: 0.8486 - val_loss: 0.5029 - val_acc: 0.7937\n",
            "Epoch 298/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3557 - acc: 0.8477 - val_loss: 0.4703 - val_acc: 0.8066\n",
            "Epoch 299/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3514 - acc: 0.8494 - val_loss: 0.4766 - val_acc: 0.8040\n",
            "Epoch 300/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3518 - acc: 0.8495 - val_loss: 0.4040 - val_acc: 0.8376\n",
            "Epoch 301/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3563 - acc: 0.8467 - val_loss: 0.4123 - val_acc: 0.8351\n",
            "Epoch 302/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3504 - acc: 0.8503 - val_loss: 0.4451 - val_acc: 0.8188\n",
            "Epoch 303/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3461 - acc: 0.8517 - val_loss: 0.4091 - val_acc: 0.8367\n",
            "Epoch 304/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3553 - acc: 0.8486 - val_loss: 0.4480 - val_acc: 0.8168\n",
            "Epoch 305/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3416 - acc: 0.8538 - val_loss: 0.4230 - val_acc: 0.8292\n",
            "Epoch 306/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3545 - acc: 0.8476 - val_loss: 0.5056 - val_acc: 0.7971\n",
            "Epoch 307/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3431 - acc: 0.8536 - val_loss: 0.4718 - val_acc: 0.8026\n",
            "Epoch 308/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3588 - acc: 0.8462 - val_loss: 0.3972 - val_acc: 0.8448\n",
            "Epoch 309/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3387 - acc: 0.8551 - val_loss: 0.3959 - val_acc: 0.8410\n",
            "Epoch 310/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3482 - acc: 0.8512 - val_loss: 0.4036 - val_acc: 0.8381\n",
            "Epoch 311/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3609 - acc: 0.8450 - val_loss: 0.3998 - val_acc: 0.8432\n",
            "Epoch 312/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3326 - acc: 0.8578 - val_loss: 0.4361 - val_acc: 0.8233\n",
            "Epoch 313/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3501 - acc: 0.8499 - val_loss: 0.4273 - val_acc: 0.8307\n",
            "Epoch 314/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3565 - acc: 0.8479 - val_loss: 0.4143 - val_acc: 0.8318\n",
            "Epoch 315/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3497 - acc: 0.8498 - val_loss: 0.3988 - val_acc: 0.8413\n",
            "Epoch 316/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3468 - acc: 0.8518 - val_loss: 0.4049 - val_acc: 0.8382\n",
            "Epoch 317/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3387 - acc: 0.8549 - val_loss: 0.4092 - val_acc: 0.8380\n",
            "Epoch 318/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3574 - acc: 0.8468 - val_loss: 0.4263 - val_acc: 0.8282\n",
            "Epoch 319/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3429 - acc: 0.8541 - val_loss: 0.3927 - val_acc: 0.8436\n",
            "Epoch 320/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3383 - acc: 0.8561 - val_loss: 0.3930 - val_acc: 0.8433\n",
            "Epoch 321/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3480 - acc: 0.8512 - val_loss: 0.4533 - val_acc: 0.8205\n",
            "Epoch 322/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3348 - acc: 0.8564 - val_loss: 0.4626 - val_acc: 0.8121\n",
            "Epoch 323/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3548 - acc: 0.8475 - val_loss: 0.4653 - val_acc: 0.8120\n",
            "Epoch 324/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3467 - acc: 0.8522 - val_loss: 0.4350 - val_acc: 0.8275\n",
            "Epoch 325/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3417 - acc: 0.8539 - val_loss: 0.3947 - val_acc: 0.8438\n",
            "Epoch 326/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3394 - acc: 0.8549 - val_loss: 0.3990 - val_acc: 0.8435\n",
            "Epoch 327/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3380 - acc: 0.8557 - val_loss: 0.4145 - val_acc: 0.8349\n",
            "Epoch 328/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3423 - acc: 0.8543 - val_loss: 0.3883 - val_acc: 0.8471\n",
            "Epoch 329/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3467 - acc: 0.8521 - val_loss: 0.4493 - val_acc: 0.8211\n",
            "Epoch 330/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3376 - acc: 0.8554 - val_loss: 0.3914 - val_acc: 0.8472\n",
            "Epoch 331/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3256 - acc: 0.8613 - val_loss: 0.4111 - val_acc: 0.8350\n",
            "Epoch 332/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3423 - acc: 0.8527 - val_loss: 0.6896 - val_acc: 0.7341\n",
            "Epoch 333/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3317 - acc: 0.8585 - val_loss: 0.3949 - val_acc: 0.8452\n",
            "Epoch 334/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3503 - acc: 0.8508 - val_loss: 0.4982 - val_acc: 0.8084\n",
            "Epoch 335/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3341 - acc: 0.8573 - val_loss: 0.6552 - val_acc: 0.7471\n",
            "Epoch 336/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3404 - acc: 0.8544 - val_loss: 0.4710 - val_acc: 0.8114\n",
            "Epoch 337/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3350 - acc: 0.8575 - val_loss: 0.4363 - val_acc: 0.8240\n",
            "Epoch 338/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3390 - acc: 0.8553 - val_loss: 0.5371 - val_acc: 0.7815\n",
            "Epoch 339/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3355 - acc: 0.8573 - val_loss: 0.3866 - val_acc: 0.8488\n",
            "Epoch 340/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3315 - acc: 0.8585 - val_loss: 0.5476 - val_acc: 0.7800\n",
            "Epoch 341/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3375 - acc: 0.8554 - val_loss: 0.4525 - val_acc: 0.8169\n",
            "Epoch 342/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3257 - acc: 0.8610 - val_loss: 0.4103 - val_acc: 0.8382\n",
            "Epoch 343/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3510 - acc: 0.8501 - val_loss: 0.4059 - val_acc: 0.8397\n",
            "Epoch 344/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3248 - acc: 0.8615 - val_loss: 0.4835 - val_acc: 0.8109\n",
            "Epoch 345/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3308 - acc: 0.8587 - val_loss: 0.5063 - val_acc: 0.7992\n",
            "Epoch 346/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3337 - acc: 0.8580 - val_loss: 0.3923 - val_acc: 0.8462\n",
            "Epoch 347/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3403 - acc: 0.8546 - val_loss: 0.4116 - val_acc: 0.8379\n",
            "Epoch 348/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3374 - acc: 0.8563 - val_loss: 0.3882 - val_acc: 0.8494\n",
            "Epoch 349/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3289 - acc: 0.8601 - val_loss: 0.4437 - val_acc: 0.8238\n",
            "Epoch 350/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3259 - acc: 0.8611 - val_loss: 0.4298 - val_acc: 0.8289\n",
            "Epoch 351/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3361 - acc: 0.8569 - val_loss: 0.4104 - val_acc: 0.8358\n",
            "Epoch 352/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3295 - acc: 0.8592 - val_loss: 0.5109 - val_acc: 0.7929\n",
            "Epoch 353/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3387 - acc: 0.8557 - val_loss: 0.4635 - val_acc: 0.8141\n",
            "Epoch 354/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3354 - acc: 0.8571 - val_loss: 0.3901 - val_acc: 0.8479\n",
            "Epoch 355/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3361 - acc: 0.8574 - val_loss: 0.3988 - val_acc: 0.8452\n",
            "Epoch 356/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3239 - acc: 0.8617 - val_loss: 0.4423 - val_acc: 0.8233\n",
            "Epoch 357/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3257 - acc: 0.8608 - val_loss: 0.3865 - val_acc: 0.8509\n",
            "Epoch 358/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3253 - acc: 0.8610 - val_loss: 0.4278 - val_acc: 0.8339\n",
            "Epoch 359/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3264 - acc: 0.8611 - val_loss: 0.4297 - val_acc: 0.8282\n",
            "Epoch 360/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3308 - acc: 0.8589 - val_loss: 0.3948 - val_acc: 0.8473\n",
            "Epoch 361/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3305 - acc: 0.8590 - val_loss: 0.4605 - val_acc: 0.8150\n",
            "Epoch 362/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3220 - acc: 0.8629 - val_loss: 0.3888 - val_acc: 0.8498\n",
            "Epoch 363/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3335 - acc: 0.8571 - val_loss: 0.3748 - val_acc: 0.8561\n",
            "Epoch 364/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3315 - acc: 0.8591 - val_loss: 0.4132 - val_acc: 0.8390\n",
            "Epoch 365/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3213 - acc: 0.8630 - val_loss: 0.4014 - val_acc: 0.8431\n",
            "Epoch 366/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3288 - acc: 0.8608 - val_loss: 0.4156 - val_acc: 0.8390\n",
            "Epoch 367/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3275 - acc: 0.8603 - val_loss: 0.4246 - val_acc: 0.8332\n",
            "Epoch 368/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3266 - acc: 0.8604 - val_loss: 0.4353 - val_acc: 0.8258\n",
            "Epoch 369/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3217 - acc: 0.8637 - val_loss: 0.4321 - val_acc: 0.8288\n",
            "Epoch 370/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3151 - acc: 0.8661 - val_loss: 0.3940 - val_acc: 0.8495\n",
            "Epoch 371/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3371 - acc: 0.8565 - val_loss: 0.4194 - val_acc: 0.8348\n",
            "Epoch 372/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3329 - acc: 0.8583 - val_loss: 0.3994 - val_acc: 0.8442\n",
            "Epoch 373/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3160 - acc: 0.8650 - val_loss: 0.4772 - val_acc: 0.8123\n",
            "Epoch 374/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3300 - acc: 0.8599 - val_loss: 0.5491 - val_acc: 0.7801\n",
            "Epoch 375/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3307 - acc: 0.8599 - val_loss: 0.4332 - val_acc: 0.8296\n",
            "Epoch 376/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3291 - acc: 0.8596 - val_loss: 0.5252 - val_acc: 0.7909\n",
            "Epoch 377/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3231 - acc: 0.8628 - val_loss: 0.4231 - val_acc: 0.8374\n",
            "Epoch 378/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3301 - acc: 0.8599 - val_loss: 0.4365 - val_acc: 0.8262\n",
            "Epoch 379/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3197 - acc: 0.8634 - val_loss: 0.4068 - val_acc: 0.8434\n",
            "Epoch 380/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3223 - acc: 0.8630 - val_loss: 0.5357 - val_acc: 0.7899\n",
            "Epoch 381/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3246 - acc: 0.8617 - val_loss: 0.5613 - val_acc: 0.7748\n",
            "Epoch 382/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.3199 - acc: 0.8635 - val_loss: 0.4134 - val_acc: 0.8387\n",
            "Epoch 383/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3201 - acc: 0.8634 - val_loss: 0.4929 - val_acc: 0.8077\n",
            "Epoch 384/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3238 - acc: 0.8622 - val_loss: 0.4039 - val_acc: 0.8442\n",
            "Epoch 385/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3163 - acc: 0.8656 - val_loss: 0.3845 - val_acc: 0.8524\n",
            "Epoch 386/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3166 - acc: 0.8651 - val_loss: 0.4462 - val_acc: 0.8240\n",
            "Epoch 387/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3119 - acc: 0.8678 - val_loss: 0.5250 - val_acc: 0.7937\n",
            "Epoch 388/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3240 - acc: 0.8618 - val_loss: 0.3887 - val_acc: 0.8513\n",
            "Epoch 389/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3285 - acc: 0.8607 - val_loss: 0.3838 - val_acc: 0.8534\n",
            "Epoch 390/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3253 - acc: 0.8611 - val_loss: 0.7073 - val_acc: 0.7359\n",
            "Epoch 391/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3207 - acc: 0.8642 - val_loss: 0.4637 - val_acc: 0.8137\n",
            "Epoch 392/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3186 - acc: 0.8650 - val_loss: 0.4406 - val_acc: 0.8241\n",
            "Epoch 393/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3216 - acc: 0.8636 - val_loss: 0.4060 - val_acc: 0.8420\n",
            "Epoch 394/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3124 - acc: 0.8672 - val_loss: 0.3829 - val_acc: 0.8529\n",
            "Epoch 395/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3200 - acc: 0.8626 - val_loss: 0.5602 - val_acc: 0.7831\n",
            "Epoch 396/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3136 - acc: 0.8664 - val_loss: 0.4621 - val_acc: 0.8201\n",
            "Epoch 397/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3165 - acc: 0.8654 - val_loss: 0.4220 - val_acc: 0.8377\n",
            "Epoch 398/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3223 - acc: 0.8625 - val_loss: 0.4050 - val_acc: 0.8449\n",
            "Epoch 399/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3130 - acc: 0.8668 - val_loss: 0.5026 - val_acc: 0.8012\n",
            "Epoch 400/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3155 - acc: 0.8652 - val_loss: 0.5536 - val_acc: 0.7909\n",
            "Epoch 401/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3124 - acc: 0.8680 - val_loss: 0.4743 - val_acc: 0.8124\n",
            "Epoch 402/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3308 - acc: 0.8593 - val_loss: 0.3984 - val_acc: 0.8442\n",
            "Epoch 403/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3184 - acc: 0.8641 - val_loss: 0.4052 - val_acc: 0.8422\n",
            "Epoch 404/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3197 - acc: 0.8637 - val_loss: 0.3942 - val_acc: 0.8487\n",
            "Epoch 405/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3147 - acc: 0.8664 - val_loss: 0.4375 - val_acc: 0.8313\n",
            "Epoch 406/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3192 - acc: 0.8646 - val_loss: 0.3877 - val_acc: 0.8522\n",
            "Epoch 407/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3209 - acc: 0.8638 - val_loss: 0.4630 - val_acc: 0.8213\n",
            "Epoch 408/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3239 - acc: 0.8622 - val_loss: 0.3975 - val_acc: 0.8473\n",
            "Epoch 409/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3235 - acc: 0.8625 - val_loss: 0.4404 - val_acc: 0.8258\n",
            "Epoch 410/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3170 - acc: 0.8653 - val_loss: 0.5421 - val_acc: 0.7933\n",
            "Epoch 411/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3175 - acc: 0.8645 - val_loss: 0.3862 - val_acc: 0.8516\n",
            "Epoch 412/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3101 - acc: 0.8679 - val_loss: 0.4002 - val_acc: 0.8453\n",
            "Epoch 413/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3154 - acc: 0.8665 - val_loss: 0.3927 - val_acc: 0.8509\n",
            "Epoch 414/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3100 - acc: 0.8680 - val_loss: 0.3863 - val_acc: 0.8536\n",
            "Epoch 415/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3173 - acc: 0.8661 - val_loss: 0.4797 - val_acc: 0.8118\n",
            "Epoch 416/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3198 - acc: 0.8639 - val_loss: 0.3990 - val_acc: 0.8486\n",
            "Epoch 417/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3121 - acc: 0.8674 - val_loss: 0.4104 - val_acc: 0.8452\n",
            "Epoch 418/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3190 - acc: 0.8643 - val_loss: 0.3902 - val_acc: 0.8522\n",
            "Epoch 419/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3018 - acc: 0.8718 - val_loss: 0.4879 - val_acc: 0.8091\n",
            "Epoch 420/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3134 - acc: 0.8673 - val_loss: 0.4106 - val_acc: 0.8425\n",
            "Epoch 421/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3235 - acc: 0.8625 - val_loss: 0.4033 - val_acc: 0.8458\n",
            "Epoch 422/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3063 - acc: 0.8704 - val_loss: 0.3780 - val_acc: 0.8584\n",
            "Epoch 423/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3079 - acc: 0.8691 - val_loss: 0.3847 - val_acc: 0.8554\n",
            "Epoch 424/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2994 - acc: 0.8732 - val_loss: 0.4143 - val_acc: 0.8427\n",
            "Epoch 425/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3188 - acc: 0.8648 - val_loss: 0.3970 - val_acc: 0.8497\n",
            "Epoch 426/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.3151 - acc: 0.8663 - val_loss: 0.4189 - val_acc: 0.8379\n",
            "Epoch 427/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3045 - acc: 0.8706 - val_loss: 0.4471 - val_acc: 0.8247\n",
            "Epoch 428/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.3116 - acc: 0.8680 - val_loss: 0.3894 - val_acc: 0.8536\n",
            "Epoch 429/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3079 - acc: 0.8695 - val_loss: 0.4363 - val_acc: 0.8311\n",
            "Epoch 430/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3130 - acc: 0.8660 - val_loss: 0.4056 - val_acc: 0.8456\n",
            "Epoch 431/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3020 - acc: 0.8721 - val_loss: 0.3993 - val_acc: 0.8477\n",
            "Epoch 432/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3191 - acc: 0.8644 - val_loss: 0.3826 - val_acc: 0.8540\n",
            "Epoch 433/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3093 - acc: 0.8691 - val_loss: 0.3944 - val_acc: 0.8491\n",
            "Epoch 434/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3037 - acc: 0.8715 - val_loss: 0.5304 - val_acc: 0.7935\n",
            "Epoch 435/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3069 - acc: 0.8693 - val_loss: 0.5317 - val_acc: 0.7915\n",
            "Epoch 436/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3056 - acc: 0.8706 - val_loss: 0.4199 - val_acc: 0.8380\n",
            "Epoch 437/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3102 - acc: 0.8681 - val_loss: 0.4278 - val_acc: 0.8368\n",
            "Epoch 438/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3133 - acc: 0.8670 - val_loss: 0.4045 - val_acc: 0.8460\n",
            "Epoch 439/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2975 - acc: 0.8737 - val_loss: 0.4008 - val_acc: 0.8497\n",
            "Epoch 440/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3168 - acc: 0.8650 - val_loss: 0.4328 - val_acc: 0.8385\n",
            "Epoch 441/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3075 - acc: 0.8698 - val_loss: 0.4376 - val_acc: 0.8372\n",
            "Epoch 442/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3062 - acc: 0.8702 - val_loss: 0.3849 - val_acc: 0.8551\n",
            "Epoch 443/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3161 - acc: 0.8659 - val_loss: 0.4189 - val_acc: 0.8431\n",
            "Epoch 444/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3011 - acc: 0.8718 - val_loss: 0.4189 - val_acc: 0.8416\n",
            "Epoch 445/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3154 - acc: 0.8657 - val_loss: 0.4044 - val_acc: 0.8476\n",
            "Epoch 446/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2948 - acc: 0.8751 - val_loss: 0.4576 - val_acc: 0.8262\n",
            "Epoch 447/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3062 - acc: 0.8703 - val_loss: 0.3924 - val_acc: 0.8520\n",
            "Epoch 448/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3003 - acc: 0.8723 - val_loss: 0.4753 - val_acc: 0.8146\n",
            "Epoch 449/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3091 - acc: 0.8685 - val_loss: 0.6491 - val_acc: 0.7604\n",
            "Epoch 450/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3080 - acc: 0.8692 - val_loss: 0.3768 - val_acc: 0.8593\n",
            "Epoch 451/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2977 - acc: 0.8730 - val_loss: 0.3935 - val_acc: 0.8521\n",
            "Epoch 452/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3099 - acc: 0.8683 - val_loss: 0.3955 - val_acc: 0.8525\n",
            "Epoch 453/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2990 - acc: 0.8727 - val_loss: 0.4098 - val_acc: 0.8460\n",
            "Epoch 454/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3039 - acc: 0.8711 - val_loss: 0.3927 - val_acc: 0.8519\n",
            "Epoch 455/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3084 - acc: 0.8685 - val_loss: 0.3927 - val_acc: 0.8538\n",
            "Epoch 456/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2960 - acc: 0.8745 - val_loss: 0.4959 - val_acc: 0.8083\n",
            "Epoch 457/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3036 - acc: 0.8711 - val_loss: 0.4086 - val_acc: 0.8473\n",
            "Epoch 458/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3012 - acc: 0.8722 - val_loss: 0.4241 - val_acc: 0.8435\n",
            "Epoch 459/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3067 - acc: 0.8695 - val_loss: 0.4334 - val_acc: 0.8380\n",
            "Epoch 460/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2948 - acc: 0.8749 - val_loss: 0.3949 - val_acc: 0.8523\n",
            "Epoch 461/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2941 - acc: 0.8760 - val_loss: 0.3846 - val_acc: 0.8576\n",
            "Epoch 462/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3159 - acc: 0.8664 - val_loss: 0.3966 - val_acc: 0.8474\n",
            "Epoch 463/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2902 - acc: 0.8772 - val_loss: 0.4327 - val_acc: 0.8347\n",
            "Epoch 464/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3007 - acc: 0.8728 - val_loss: 0.3956 - val_acc: 0.8517\n",
            "Epoch 465/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2954 - acc: 0.8747 - val_loss: 0.4351 - val_acc: 0.8358\n",
            "Epoch 466/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3037 - acc: 0.8716 - val_loss: 0.3844 - val_acc: 0.8572\n",
            "Epoch 467/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2954 - acc: 0.8746 - val_loss: 0.5209 - val_acc: 0.8028\n",
            "Epoch 468/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3063 - acc: 0.8709 - val_loss: 0.5020 - val_acc: 0.8078\n",
            "Epoch 469/750\n",
            "245114/245114 [==============================] - 8s 32us/sample - loss: 0.3050 - acc: 0.8705 - val_loss: 0.4203 - val_acc: 0.8377\n",
            "Epoch 470/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2984 - acc: 0.8738 - val_loss: 0.3741 - val_acc: 0.8613\n",
            "Epoch 471/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2946 - acc: 0.8747 - val_loss: 0.3754 - val_acc: 0.8617\n",
            "Epoch 472/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3032 - acc: 0.8714 - val_loss: 0.4090 - val_acc: 0.8448\n",
            "Epoch 473/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2947 - acc: 0.8744 - val_loss: 0.4103 - val_acc: 0.8455\n",
            "Epoch 474/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3010 - acc: 0.8731 - val_loss: 0.5405 - val_acc: 0.7909\n",
            "Epoch 475/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2995 - acc: 0.8735 - val_loss: 0.4380 - val_acc: 0.8351\n",
            "Epoch 476/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3061 - acc: 0.8702 - val_loss: 0.4224 - val_acc: 0.8407\n",
            "Epoch 477/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3038 - acc: 0.8709 - val_loss: 0.4090 - val_acc: 0.8472\n",
            "Epoch 478/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2913 - acc: 0.8767 - val_loss: 0.4004 - val_acc: 0.8520\n",
            "Epoch 479/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2974 - acc: 0.8745 - val_loss: 0.4029 - val_acc: 0.8485\n",
            "Epoch 480/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3087 - acc: 0.8704 - val_loss: 0.4160 - val_acc: 0.8429\n",
            "Epoch 481/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2947 - acc: 0.8757 - val_loss: 0.5593 - val_acc: 0.7889\n",
            "Epoch 482/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2925 - acc: 0.8768 - val_loss: 0.3882 - val_acc: 0.8574\n",
            "Epoch 483/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3056 - acc: 0.8713 - val_loss: 0.3941 - val_acc: 0.8523\n",
            "Epoch 484/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3052 - acc: 0.8702 - val_loss: 0.4094 - val_acc: 0.8464\n",
            "Epoch 485/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2847 - acc: 0.8796 - val_loss: 0.3777 - val_acc: 0.8610\n",
            "Epoch 486/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3019 - acc: 0.8718 - val_loss: 0.4149 - val_acc: 0.8452\n",
            "Epoch 487/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2886 - acc: 0.8780 - val_loss: 0.3927 - val_acc: 0.8545\n",
            "Epoch 488/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2926 - acc: 0.8754 - val_loss: 0.4858 - val_acc: 0.8138\n",
            "Epoch 489/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2965 - acc: 0.8747 - val_loss: 0.4718 - val_acc: 0.8178\n",
            "Epoch 490/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2916 - acc: 0.8762 - val_loss: 0.4153 - val_acc: 0.8472\n",
            "Epoch 491/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2926 - acc: 0.8758 - val_loss: 0.4703 - val_acc: 0.8205\n",
            "Epoch 492/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3049 - acc: 0.8719 - val_loss: 0.3857 - val_acc: 0.8588\n",
            "Epoch 493/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2872 - acc: 0.8788 - val_loss: 0.4109 - val_acc: 0.8486\n",
            "Epoch 494/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2921 - acc: 0.8764 - val_loss: 0.4060 - val_acc: 0.8511\n",
            "Epoch 495/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2899 - acc: 0.8772 - val_loss: 0.4131 - val_acc: 0.8458\n",
            "Epoch 496/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2973 - acc: 0.8739 - val_loss: 0.4057 - val_acc: 0.8489\n",
            "Epoch 497/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2921 - acc: 0.8761 - val_loss: 0.4034 - val_acc: 0.8533\n",
            "Epoch 498/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2917 - acc: 0.8763 - val_loss: 0.4037 - val_acc: 0.8492\n",
            "Epoch 499/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2903 - acc: 0.8776 - val_loss: 0.4469 - val_acc: 0.8318\n",
            "Epoch 500/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2887 - acc: 0.8778 - val_loss: 0.4066 - val_acc: 0.8514\n",
            "Epoch 501/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2919 - acc: 0.8767 - val_loss: 0.3886 - val_acc: 0.8572\n",
            "Epoch 502/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2966 - acc: 0.8743 - val_loss: 0.5128 - val_acc: 0.8023\n",
            "Epoch 503/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2965 - acc: 0.8744 - val_loss: 0.4039 - val_acc: 0.8530\n",
            "Epoch 504/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2833 - acc: 0.8805 - val_loss: 0.3984 - val_acc: 0.8542\n",
            "Epoch 505/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2994 - acc: 0.8732 - val_loss: 0.4002 - val_acc: 0.8516\n",
            "Epoch 506/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2869 - acc: 0.8789 - val_loss: 0.3763 - val_acc: 0.8610\n",
            "Epoch 507/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2864 - acc: 0.8786 - val_loss: 0.4067 - val_acc: 0.8508\n",
            "Epoch 508/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3047 - acc: 0.8709 - val_loss: 0.3801 - val_acc: 0.8598\n",
            "Epoch 509/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2842 - acc: 0.8796 - val_loss: 0.4272 - val_acc: 0.8394\n",
            "Epoch 510/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2852 - acc: 0.8794 - val_loss: 0.4568 - val_acc: 0.8293\n",
            "Epoch 511/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2958 - acc: 0.8749 - val_loss: 0.4135 - val_acc: 0.8465\n",
            "Epoch 512/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.2897 - acc: 0.8773 - val_loss: 0.3806 - val_acc: 0.8623\n",
            "Epoch 513/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2832 - acc: 0.8802 - val_loss: 0.3912 - val_acc: 0.8587\n",
            "Epoch 514/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2900 - acc: 0.8765 - val_loss: 0.4120 - val_acc: 0.8507\n",
            "Epoch 515/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2952 - acc: 0.8748 - val_loss: 0.4629 - val_acc: 0.8251\n",
            "Epoch 516/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2986 - acc: 0.8735 - val_loss: 0.3875 - val_acc: 0.8604\n",
            "Epoch 517/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2861 - acc: 0.8789 - val_loss: 0.3944 - val_acc: 0.8562\n",
            "Epoch 518/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2861 - acc: 0.8790 - val_loss: 0.4504 - val_acc: 0.8262\n",
            "Epoch 519/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2969 - acc: 0.8745 - val_loss: 0.4076 - val_acc: 0.8504\n",
            "Epoch 520/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2878 - acc: 0.8781 - val_loss: 0.3738 - val_acc: 0.8637\n",
            "Epoch 521/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2812 - acc: 0.8816 - val_loss: 0.3965 - val_acc: 0.8542\n",
            "Epoch 522/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2969 - acc: 0.8754 - val_loss: 0.4010 - val_acc: 0.8528\n",
            "Epoch 523/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2935 - acc: 0.8758 - val_loss: 0.4862 - val_acc: 0.8173\n",
            "Epoch 524/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2849 - acc: 0.8794 - val_loss: 0.4058 - val_acc: 0.8519\n",
            "Epoch 525/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2876 - acc: 0.8783 - val_loss: 0.4080 - val_acc: 0.8498\n",
            "Epoch 526/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2829 - acc: 0.8805 - val_loss: 0.4374 - val_acc: 0.8350\n",
            "Epoch 527/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.3003 - acc: 0.8731 - val_loss: 0.4000 - val_acc: 0.8551\n",
            "Epoch 528/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2951 - acc: 0.8754 - val_loss: 0.4993 - val_acc: 0.8135\n",
            "Epoch 529/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2843 - acc: 0.8798 - val_loss: 0.4325 - val_acc: 0.8389\n",
            "Epoch 530/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2863 - acc: 0.8794 - val_loss: 0.4022 - val_acc: 0.8531\n",
            "Epoch 531/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.3068 - acc: 0.8712 - val_loss: 0.3682 - val_acc: 0.8668\n",
            "Epoch 532/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2868 - acc: 0.8782 - val_loss: 0.3815 - val_acc: 0.8614\n",
            "Epoch 533/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2747 - acc: 0.8841 - val_loss: 0.4031 - val_acc: 0.8518\n",
            "Epoch 534/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2805 - acc: 0.8819 - val_loss: 0.3758 - val_acc: 0.8642\n",
            "Epoch 535/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2981 - acc: 0.8746 - val_loss: 0.3889 - val_acc: 0.8588\n",
            "Epoch 536/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2819 - acc: 0.8811 - val_loss: 0.3940 - val_acc: 0.8576\n",
            "Epoch 537/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2912 - acc: 0.8780 - val_loss: 0.3908 - val_acc: 0.8579\n",
            "Epoch 538/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2825 - acc: 0.8798 - val_loss: 0.3955 - val_acc: 0.8570\n",
            "Epoch 539/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2789 - acc: 0.8827 - val_loss: 0.4060 - val_acc: 0.8508\n",
            "Epoch 540/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2916 - acc: 0.8771 - val_loss: 0.3828 - val_acc: 0.8624\n",
            "Epoch 541/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2854 - acc: 0.8803 - val_loss: 0.4301 - val_acc: 0.8396\n",
            "Epoch 542/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2914 - acc: 0.8774 - val_loss: 0.3978 - val_acc: 0.8556\n",
            "Epoch 543/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2818 - acc: 0.8808 - val_loss: 0.5465 - val_acc: 0.7926\n",
            "Epoch 544/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2940 - acc: 0.8760 - val_loss: 0.3744 - val_acc: 0.8659\n",
            "Epoch 545/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2771 - acc: 0.8835 - val_loss: 0.3825 - val_acc: 0.8630\n",
            "Epoch 546/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2868 - acc: 0.8795 - val_loss: 0.3964 - val_acc: 0.8557\n",
            "Epoch 547/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2793 - acc: 0.8823 - val_loss: 0.4050 - val_acc: 0.8518\n",
            "Epoch 548/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2895 - acc: 0.8786 - val_loss: 0.4154 - val_acc: 0.8475\n",
            "Epoch 549/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2821 - acc: 0.8810 - val_loss: 0.3826 - val_acc: 0.8607\n",
            "Epoch 550/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2907 - acc: 0.8767 - val_loss: 0.5701 - val_acc: 0.7920\n",
            "Epoch 551/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2838 - acc: 0.8803 - val_loss: 0.4672 - val_acc: 0.8264\n",
            "Epoch 552/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2841 - acc: 0.8803 - val_loss: 0.4268 - val_acc: 0.8459\n",
            "Epoch 553/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2843 - acc: 0.8800 - val_loss: 0.4629 - val_acc: 0.8323\n",
            "Epoch 554/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2824 - acc: 0.8816 - val_loss: 0.4095 - val_acc: 0.8485\n",
            "Epoch 555/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.2873 - acc: 0.8780 - val_loss: 0.4192 - val_acc: 0.8466\n",
            "Epoch 556/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2820 - acc: 0.8806 - val_loss: 0.4076 - val_acc: 0.8545\n",
            "Epoch 557/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2938 - acc: 0.8754 - val_loss: 0.3927 - val_acc: 0.8589\n",
            "Epoch 558/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2817 - acc: 0.8818 - val_loss: 0.5302 - val_acc: 0.8069\n",
            "Epoch 559/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2894 - acc: 0.8773 - val_loss: 0.3785 - val_acc: 0.8643\n",
            "Epoch 560/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2809 - acc: 0.8808 - val_loss: 0.3782 - val_acc: 0.8652\n",
            "Epoch 561/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2748 - acc: 0.8843 - val_loss: 0.3894 - val_acc: 0.8600\n",
            "Epoch 562/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2816 - acc: 0.8816 - val_loss: 0.4474 - val_acc: 0.8292\n",
            "Epoch 563/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2878 - acc: 0.8791 - val_loss: 0.4864 - val_acc: 0.8176\n",
            "Epoch 564/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2798 - acc: 0.8820 - val_loss: 0.3744 - val_acc: 0.8654\n",
            "Epoch 565/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2847 - acc: 0.8797 - val_loss: 0.4316 - val_acc: 0.8422\n",
            "Epoch 566/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2852 - acc: 0.8801 - val_loss: 0.4326 - val_acc: 0.8389\n",
            "Epoch 567/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2845 - acc: 0.8794 - val_loss: 0.3936 - val_acc: 0.8580\n",
            "Epoch 568/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2722 - acc: 0.8850 - val_loss: 0.4535 - val_acc: 0.8317\n",
            "Epoch 569/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2913 - acc: 0.8769 - val_loss: 0.4364 - val_acc: 0.8397\n",
            "Epoch 570/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2810 - acc: 0.8814 - val_loss: 0.4020 - val_acc: 0.8555\n",
            "Epoch 571/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2714 - acc: 0.8859 - val_loss: 0.4684 - val_acc: 0.8276\n",
            "Epoch 572/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2818 - acc: 0.8810 - val_loss: 0.4021 - val_acc: 0.8551\n",
            "Epoch 573/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2746 - acc: 0.8850 - val_loss: 0.3934 - val_acc: 0.8590\n",
            "Epoch 574/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2814 - acc: 0.8808 - val_loss: 0.3905 - val_acc: 0.8594\n",
            "Epoch 575/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2789 - acc: 0.8819 - val_loss: 0.6137 - val_acc: 0.7766\n",
            "Epoch 576/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2803 - acc: 0.8823 - val_loss: 0.3880 - val_acc: 0.8621\n",
            "Epoch 577/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2957 - acc: 0.8752 - val_loss: 0.3816 - val_acc: 0.8650\n",
            "Epoch 578/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2809 - acc: 0.8825 - val_loss: 0.3947 - val_acc: 0.8558\n",
            "Epoch 579/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2738 - acc: 0.8844 - val_loss: 0.4051 - val_acc: 0.8560\n",
            "Epoch 580/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2812 - acc: 0.8809 - val_loss: 0.4847 - val_acc: 0.8149\n",
            "Epoch 581/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2758 - acc: 0.8841 - val_loss: 0.4126 - val_acc: 0.8518\n",
            "Epoch 582/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2781 - acc: 0.8832 - val_loss: 0.3992 - val_acc: 0.8575\n",
            "Epoch 583/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2777 - acc: 0.8827 - val_loss: 0.4625 - val_acc: 0.8324\n",
            "Epoch 584/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2688 - acc: 0.8865 - val_loss: 0.3909 - val_acc: 0.8600\n",
            "Epoch 585/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2833 - acc: 0.8812 - val_loss: 0.4097 - val_acc: 0.8526\n",
            "Epoch 586/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2769 - acc: 0.8833 - val_loss: 0.4010 - val_acc: 0.8568\n",
            "Epoch 587/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2906 - acc: 0.8782 - val_loss: 0.3929 - val_acc: 0.8590\n",
            "Epoch 588/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2728 - acc: 0.8849 - val_loss: 0.3995 - val_acc: 0.8581\n",
            "Epoch 589/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2715 - acc: 0.8858 - val_loss: 0.4340 - val_acc: 0.8441\n",
            "Epoch 590/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2726 - acc: 0.8846 - val_loss: 0.3934 - val_acc: 0.8589\n",
            "Epoch 591/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2741 - acc: 0.8846 - val_loss: 0.3992 - val_acc: 0.8591\n",
            "Epoch 592/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2721 - acc: 0.8851 - val_loss: 0.4550 - val_acc: 0.8349\n",
            "Epoch 593/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2808 - acc: 0.8817 - val_loss: 0.3813 - val_acc: 0.8631\n",
            "Epoch 594/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2844 - acc: 0.8805 - val_loss: 0.4409 - val_acc: 0.8384\n",
            "Epoch 595/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2682 - acc: 0.8873 - val_loss: 0.4103 - val_acc: 0.8536\n",
            "Epoch 596/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2784 - acc: 0.8825 - val_loss: 0.4258 - val_acc: 0.8449\n",
            "Epoch 597/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2760 - acc: 0.8836 - val_loss: 0.4005 - val_acc: 0.8581\n",
            "Epoch 598/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.2716 - acc: 0.8853 - val_loss: 0.4941 - val_acc: 0.8198\n",
            "Epoch 599/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2739 - acc: 0.8854 - val_loss: 0.3798 - val_acc: 0.8654\n",
            "Epoch 600/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2694 - acc: 0.8866 - val_loss: 0.4399 - val_acc: 0.8409\n",
            "Epoch 601/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2784 - acc: 0.8827 - val_loss: 0.4254 - val_acc: 0.8459\n",
            "Epoch 602/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2834 - acc: 0.8817 - val_loss: 0.4218 - val_acc: 0.8493\n",
            "Epoch 603/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2795 - acc: 0.8821 - val_loss: 0.3943 - val_acc: 0.8612\n",
            "Epoch 604/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2716 - acc: 0.8858 - val_loss: 0.3922 - val_acc: 0.8610\n",
            "Epoch 605/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2764 - acc: 0.8833 - val_loss: 0.5183 - val_acc: 0.8136\n",
            "Epoch 606/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2627 - acc: 0.8896 - val_loss: 0.4091 - val_acc: 0.8533\n",
            "Epoch 607/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2789 - acc: 0.8823 - val_loss: 0.4389 - val_acc: 0.8411\n",
            "Epoch 608/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2705 - acc: 0.8858 - val_loss: 0.4970 - val_acc: 0.8190\n",
            "Epoch 609/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2818 - acc: 0.8816 - val_loss: 0.4004 - val_acc: 0.8577\n",
            "Epoch 610/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2693 - acc: 0.8873 - val_loss: 0.4071 - val_acc: 0.8543\n",
            "Epoch 611/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2823 - acc: 0.8812 - val_loss: 0.3884 - val_acc: 0.8634\n",
            "Epoch 612/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2740 - acc: 0.8844 - val_loss: 0.3885 - val_acc: 0.8626\n",
            "Epoch 613/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2659 - acc: 0.8886 - val_loss: 0.3930 - val_acc: 0.8628\n",
            "Epoch 614/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2797 - acc: 0.8829 - val_loss: 0.4642 - val_acc: 0.8329\n",
            "Epoch 615/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2735 - acc: 0.8849 - val_loss: 0.3855 - val_acc: 0.8652\n",
            "Epoch 616/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2752 - acc: 0.8843 - val_loss: 0.3955 - val_acc: 0.8618\n",
            "Epoch 617/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2762 - acc: 0.8837 - val_loss: 0.3892 - val_acc: 0.8622\n",
            "Epoch 618/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2738 - acc: 0.8846 - val_loss: 0.3952 - val_acc: 0.8610\n",
            "Epoch 619/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2887 - acc: 0.8795 - val_loss: 0.4471 - val_acc: 0.8365\n",
            "Epoch 620/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2660 - acc: 0.8882 - val_loss: 0.4642 - val_acc: 0.8304\n",
            "Epoch 621/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2674 - acc: 0.8880 - val_loss: 0.3960 - val_acc: 0.8623\n",
            "Epoch 622/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2671 - acc: 0.8886 - val_loss: 0.3787 - val_acc: 0.8669\n",
            "Epoch 623/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2755 - acc: 0.8844 - val_loss: 0.3984 - val_acc: 0.8587\n",
            "Epoch 624/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2667 - acc: 0.8882 - val_loss: 0.4412 - val_acc: 0.8395\n",
            "Epoch 625/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2984 - acc: 0.8746 - val_loss: 0.4309 - val_acc: 0.8416\n",
            "Epoch 626/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2662 - acc: 0.8889 - val_loss: 0.3728 - val_acc: 0.8715\n",
            "Epoch 627/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2755 - acc: 0.8844 - val_loss: 0.4075 - val_acc: 0.8563\n",
            "Epoch 628/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2696 - acc: 0.8870 - val_loss: 0.3814 - val_acc: 0.8681\n",
            "Epoch 629/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2768 - acc: 0.8845 - val_loss: 0.3907 - val_acc: 0.8621\n",
            "Epoch 630/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2640 - acc: 0.8896 - val_loss: 0.4229 - val_acc: 0.8504\n",
            "Epoch 631/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2855 - acc: 0.8798 - val_loss: 0.4980 - val_acc: 0.8163\n",
            "Epoch 632/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2656 - acc: 0.8884 - val_loss: 0.4386 - val_acc: 0.8472\n",
            "Epoch 633/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2716 - acc: 0.8865 - val_loss: 0.3760 - val_acc: 0.8704\n",
            "Epoch 634/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2675 - acc: 0.8880 - val_loss: 0.5101 - val_acc: 0.8135\n",
            "Epoch 635/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2754 - acc: 0.8847 - val_loss: 0.3802 - val_acc: 0.8683\n",
            "Epoch 636/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2722 - acc: 0.8862 - val_loss: 0.4173 - val_acc: 0.8506\n",
            "Epoch 637/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2738 - acc: 0.8847 - val_loss: 0.3850 - val_acc: 0.8642\n",
            "Epoch 638/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2700 - acc: 0.8868 - val_loss: 0.3900 - val_acc: 0.8632\n",
            "Epoch 639/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2707 - acc: 0.8859 - val_loss: 0.4160 - val_acc: 0.8517\n",
            "Epoch 640/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2752 - acc: 0.8844 - val_loss: 0.3837 - val_acc: 0.8676\n",
            "Epoch 641/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2813 - acc: 0.8823 - val_loss: 0.4218 - val_acc: 0.8500\n",
            "Epoch 642/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2655 - acc: 0.8884 - val_loss: 0.3840 - val_acc: 0.8664\n",
            "Epoch 643/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2593 - acc: 0.8914 - val_loss: 0.4219 - val_acc: 0.8484\n",
            "Epoch 644/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2710 - acc: 0.8857 - val_loss: 0.4122 - val_acc: 0.8547\n",
            "Epoch 645/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2659 - acc: 0.8879 - val_loss: 0.4015 - val_acc: 0.8596\n",
            "Epoch 646/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2685 - acc: 0.8870 - val_loss: 0.5025 - val_acc: 0.8152\n",
            "Epoch 647/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2691 - acc: 0.8863 - val_loss: 0.4148 - val_acc: 0.8505\n",
            "Epoch 648/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2785 - acc: 0.8830 - val_loss: 0.4332 - val_acc: 0.8423\n",
            "Epoch 649/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2647 - acc: 0.8889 - val_loss: 0.3905 - val_acc: 0.8634\n",
            "Epoch 650/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2681 - acc: 0.8879 - val_loss: 0.3764 - val_acc: 0.8703\n",
            "Epoch 651/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2603 - acc: 0.8909 - val_loss: 0.4202 - val_acc: 0.8522\n",
            "Epoch 652/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2684 - acc: 0.8864 - val_loss: 0.4286 - val_acc: 0.8480\n",
            "Epoch 653/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2670 - acc: 0.8878 - val_loss: 0.5646 - val_acc: 0.7980\n",
            "Epoch 654/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2709 - acc: 0.8866 - val_loss: 0.5736 - val_acc: 0.7984\n",
            "Epoch 655/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2668 - acc: 0.8891 - val_loss: 0.4255 - val_acc: 0.8496\n",
            "Epoch 656/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2762 - acc: 0.8841 - val_loss: 0.4220 - val_acc: 0.8521\n",
            "Epoch 657/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2788 - acc: 0.8824 - val_loss: 0.4442 - val_acc: 0.8416\n",
            "Epoch 658/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2562 - acc: 0.8922 - val_loss: 0.3910 - val_acc: 0.8641\n",
            "Epoch 659/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2780 - acc: 0.8839 - val_loss: 0.4018 - val_acc: 0.8596\n",
            "Epoch 660/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2709 - acc: 0.8865 - val_loss: 0.4045 - val_acc: 0.8590\n",
            "Epoch 661/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2637 - acc: 0.8898 - val_loss: 0.4119 - val_acc: 0.8569\n",
            "Epoch 662/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2622 - acc: 0.8903 - val_loss: 0.4564 - val_acc: 0.8359\n",
            "Epoch 663/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2657 - acc: 0.8888 - val_loss: 0.3924 - val_acc: 0.8639\n",
            "Epoch 664/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2662 - acc: 0.8880 - val_loss: 0.4617 - val_acc: 0.8343\n",
            "Epoch 665/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2720 - acc: 0.8858 - val_loss: 0.3941 - val_acc: 0.8625\n",
            "Epoch 666/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2738 - acc: 0.8852 - val_loss: 0.4801 - val_acc: 0.8260\n",
            "Epoch 667/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2589 - acc: 0.8917 - val_loss: 0.4643 - val_acc: 0.8322\n",
            "Epoch 668/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2774 - acc: 0.8836 - val_loss: 0.4085 - val_acc: 0.8564\n",
            "Epoch 669/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2548 - acc: 0.8934 - val_loss: 0.3876 - val_acc: 0.8663\n",
            "Epoch 670/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2785 - acc: 0.8843 - val_loss: 0.4968 - val_acc: 0.8228\n",
            "Epoch 671/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2577 - acc: 0.8915 - val_loss: 0.3960 - val_acc: 0.8614\n",
            "Epoch 672/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2623 - acc: 0.8903 - val_loss: 0.3979 - val_acc: 0.8627\n",
            "Epoch 673/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2574 - acc: 0.8924 - val_loss: 0.4514 - val_acc: 0.8367\n",
            "Epoch 674/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2686 - acc: 0.8868 - val_loss: 0.4384 - val_acc: 0.8462\n",
            "Epoch 675/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2693 - acc: 0.8874 - val_loss: 0.4217 - val_acc: 0.8505\n",
            "Epoch 676/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2767 - acc: 0.8843 - val_loss: 0.4285 - val_acc: 0.8457\n",
            "Epoch 677/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2663 - acc: 0.8886 - val_loss: 0.3774 - val_acc: 0.8696\n",
            "Epoch 678/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2577 - acc: 0.8923 - val_loss: 0.4126 - val_acc: 0.8572\n",
            "Epoch 679/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2717 - acc: 0.8868 - val_loss: 0.4237 - val_acc: 0.8544\n",
            "Epoch 680/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2592 - acc: 0.8909 - val_loss: 0.4511 - val_acc: 0.8349\n",
            "Epoch 681/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2582 - acc: 0.8915 - val_loss: 0.3827 - val_acc: 0.8679\n",
            "Epoch 682/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2558 - acc: 0.8930 - val_loss: 0.4163 - val_acc: 0.8552\n",
            "Epoch 683/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2678 - acc: 0.8883 - val_loss: 0.3800 - val_acc: 0.8695\n",
            "Epoch 684/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2659 - acc: 0.8895 - val_loss: 0.3836 - val_acc: 0.8681\n",
            "Epoch 685/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2738 - acc: 0.8848 - val_loss: 0.5453 - val_acc: 0.8004\n",
            "Epoch 686/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2539 - acc: 0.8936 - val_loss: 0.4722 - val_acc: 0.8291\n",
            "Epoch 687/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2617 - acc: 0.8909 - val_loss: 0.4715 - val_acc: 0.8354\n",
            "Epoch 688/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2657 - acc: 0.8893 - val_loss: 0.4282 - val_acc: 0.8513\n",
            "Epoch 689/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2536 - acc: 0.8939 - val_loss: 0.3982 - val_acc: 0.8638\n",
            "Epoch 690/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2730 - acc: 0.8862 - val_loss: 0.4155 - val_acc: 0.8532\n",
            "Epoch 691/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2546 - acc: 0.8934 - val_loss: 0.3895 - val_acc: 0.8679\n",
            "Epoch 692/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2583 - acc: 0.8922 - val_loss: 0.4318 - val_acc: 0.8486\n",
            "Epoch 693/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2656 - acc: 0.8884 - val_loss: 0.3844 - val_acc: 0.8678\n",
            "Epoch 694/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2567 - acc: 0.8924 - val_loss: 0.3825 - val_acc: 0.8685\n",
            "Epoch 695/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2578 - acc: 0.8923 - val_loss: 0.4728 - val_acc: 0.8359\n",
            "Epoch 696/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2679 - acc: 0.8886 - val_loss: 0.3940 - val_acc: 0.8645\n",
            "Epoch 697/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2767 - acc: 0.8853 - val_loss: 0.4093 - val_acc: 0.8576\n",
            "Epoch 698/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2593 - acc: 0.8917 - val_loss: 0.4219 - val_acc: 0.8520\n",
            "Epoch 699/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2608 - acc: 0.8906 - val_loss: 0.4916 - val_acc: 0.8228\n",
            "Epoch 700/750\n",
            "245114/245114 [==============================] - 7s 28us/sample - loss: 0.2623 - acc: 0.8905 - val_loss: 0.3877 - val_acc: 0.8681\n",
            "Epoch 701/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2690 - acc: 0.8880 - val_loss: 0.4275 - val_acc: 0.8502\n",
            "Epoch 702/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2541 - acc: 0.8933 - val_loss: 0.3849 - val_acc: 0.8691\n",
            "Epoch 703/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2587 - acc: 0.8919 - val_loss: 0.3905 - val_acc: 0.8665\n",
            "Epoch 704/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2596 - acc: 0.8916 - val_loss: 0.4607 - val_acc: 0.8401\n",
            "Epoch 705/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2655 - acc: 0.8890 - val_loss: 0.3991 - val_acc: 0.8619\n",
            "Epoch 706/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2606 - acc: 0.8910 - val_loss: 0.3921 - val_acc: 0.8659\n",
            "Epoch 707/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2618 - acc: 0.8898 - val_loss: 0.4022 - val_acc: 0.8632\n",
            "Epoch 708/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2612 - acc: 0.8901 - val_loss: 0.3927 - val_acc: 0.8652\n",
            "Epoch 709/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2594 - acc: 0.8917 - val_loss: 0.4357 - val_acc: 0.8473\n",
            "Epoch 710/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2684 - acc: 0.8878 - val_loss: 0.5325 - val_acc: 0.8129\n",
            "Epoch 711/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2594 - acc: 0.8923 - val_loss: 0.4051 - val_acc: 0.8616\n",
            "Epoch 712/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2607 - acc: 0.8904 - val_loss: 0.4340 - val_acc: 0.8455\n",
            "Epoch 713/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2649 - acc: 0.8886 - val_loss: 0.5847 - val_acc: 0.7971\n",
            "Epoch 714/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2598 - acc: 0.8915 - val_loss: 0.4039 - val_acc: 0.8594\n",
            "Epoch 715/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2569 - acc: 0.8928 - val_loss: 0.3835 - val_acc: 0.8702\n",
            "Epoch 716/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2633 - acc: 0.8904 - val_loss: 0.4100 - val_acc: 0.8618\n",
            "Epoch 717/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2555 - acc: 0.8929 - val_loss: 0.4331 - val_acc: 0.8504\n",
            "Epoch 718/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2669 - acc: 0.8883 - val_loss: 0.3851 - val_acc: 0.8703\n",
            "Epoch 719/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2541 - acc: 0.8952 - val_loss: 0.4307 - val_acc: 0.8515\n",
            "Epoch 720/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2608 - acc: 0.8908 - val_loss: 0.4763 - val_acc: 0.8291\n",
            "Epoch 721/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2546 - acc: 0.8939 - val_loss: 0.4723 - val_acc: 0.8338\n",
            "Epoch 722/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2630 - acc: 0.8899 - val_loss: 0.4188 - val_acc: 0.8541\n",
            "Epoch 723/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2602 - acc: 0.8909 - val_loss: 0.4075 - val_acc: 0.8606\n",
            "Epoch 724/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2521 - acc: 0.8944 - val_loss: 0.4194 - val_acc: 0.8555\n",
            "Epoch 725/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2623 - acc: 0.8906 - val_loss: 0.3859 - val_acc: 0.8691\n",
            "Epoch 726/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2517 - acc: 0.8950 - val_loss: 0.4008 - val_acc: 0.8603\n",
            "Epoch 727/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2591 - acc: 0.8917 - val_loss: 0.3878 - val_acc: 0.8694\n",
            "Epoch 728/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.2722 - acc: 0.8870 - val_loss: 0.5824 - val_acc: 0.7956\n",
            "Epoch 729/750\n",
            "245114/245114 [==============================] - 8s 31us/sample - loss: 0.2550 - acc: 0.8939 - val_loss: 0.4317 - val_acc: 0.8478\n",
            "Epoch 730/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2683 - acc: 0.8873 - val_loss: 0.4605 - val_acc: 0.8327\n",
            "Epoch 731/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2596 - acc: 0.8919 - val_loss: 0.4277 - val_acc: 0.8538\n",
            "Epoch 732/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2441 - acc: 0.8985 - val_loss: 0.4263 - val_acc: 0.8503\n",
            "Epoch 733/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2597 - acc: 0.8914 - val_loss: 0.4018 - val_acc: 0.8648\n",
            "Epoch 734/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2551 - acc: 0.8930 - val_loss: 0.3877 - val_acc: 0.8683\n",
            "Epoch 735/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2624 - acc: 0.8906 - val_loss: 0.3937 - val_acc: 0.8654\n",
            "Epoch 736/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2549 - acc: 0.8937 - val_loss: 0.4137 - val_acc: 0.8585\n",
            "Epoch 737/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2533 - acc: 0.8941 - val_loss: 0.4323 - val_acc: 0.8537\n",
            "Epoch 738/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2600 - acc: 0.8905 - val_loss: 0.4396 - val_acc: 0.8447\n",
            "Epoch 739/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2500 - acc: 0.8959 - val_loss: 0.3946 - val_acc: 0.8663\n",
            "Epoch 740/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2644 - acc: 0.8892 - val_loss: 0.3886 - val_acc: 0.8667\n",
            "Epoch 741/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2618 - acc: 0.8909 - val_loss: 0.4464 - val_acc: 0.8437\n",
            "Epoch 742/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2469 - acc: 0.8965 - val_loss: 0.4084 - val_acc: 0.8626\n",
            "Epoch 743/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2505 - acc: 0.8949 - val_loss: 0.3866 - val_acc: 0.8685\n",
            "Epoch 744/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2474 - acc: 0.8970 - val_loss: 0.5587 - val_acc: 0.8062\n",
            "Epoch 745/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2684 - acc: 0.8885 - val_loss: 0.4005 - val_acc: 0.8635\n",
            "Epoch 746/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2601 - acc: 0.8907 - val_loss: 0.4008 - val_acc: 0.8628\n",
            "Epoch 747/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2528 - acc: 0.8939 - val_loss: 0.3922 - val_acc: 0.8697\n",
            "Epoch 748/750\n",
            "245114/245114 [==============================] - 7s 30us/sample - loss: 0.2553 - acc: 0.8938 - val_loss: 0.4078 - val_acc: 0.8633\n",
            "Epoch 749/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2503 - acc: 0.8955 - val_loss: 0.3990 - val_acc: 0.8643\n",
            "Epoch 750/750\n",
            "245114/245114 [==============================] - 7s 29us/sample - loss: 0.2704 - acc: 0.8879 - val_loss: 0.5763 - val_acc: 0.7973\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GWQ2J1AMRlo",
        "colab_type": "code",
        "outputId": "505bfff3-0be6-47fe-c02d-e7dc0efcb092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(prediction2)\n",
        "\n",
        "np.savetxt(\"nnpred501.csv\", prediction2, delimiter=\",\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 1 ... 2 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smtEnpoypWXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('nnpred502.csv', 'w') as f:\n",
        "  f.write('np.savetxt(\"nnpred501.csv\", prediction2, delimiter=\",\")')\n",
        "\n",
        "files.download('nnpred502.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKfRxb5MoJwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"nnpred501.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh3-9VM1pdLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}